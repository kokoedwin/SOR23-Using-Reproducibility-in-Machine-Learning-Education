{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Grad-CAM"
   ],
   "id": "8e160c2b-fbff-4ca1-9c5d-3864c17a6369"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is Grad-CAM?\n",
    "\n",
    "Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique that provides visual explanations for decisions made by Convolutional Neural Network (CNN) models. It uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.\n",
    "\n",
    "Grad-CAM is not limited to a specific architecture, it can be applied to a wide range of CNN models without any changes to their existing structure or requiring re-training. It’s also class-discriminative, allowing it to effectively manage multi-label scenarios.\n",
    "\n",
    "By visualizing the model’s focus areas with Grad-CAM, we can assess how effectively Cutout is encouraging the model to use a broader range of features. For example, if a model trained with Cutout still primarily focuses on a single region, that might suggest the Cutout squares are too small, or not numerous enough. Conversely, if the focus areas are well spread across the image, it would confirm that Cutout is indeed pushing the model to generalize better.\n",
    "\n",
    "If you want to understand more about Grad-CAM? Check this paper (https://arxiv.org/abs/1610.02391)"
   ],
   "id": "3d45afbd-ff6e-4c98-bb0f-cc259b8b9e54"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ],
   "id": "5a56ee3c-080e-4972-9fa2-b849a3873255"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ],
   "id": "f90d3498-4293-4cf3-8875-eac7532d551d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Cuda GPU availability and set seed number"
   ],
   "id": "a3168fbe-9a7c-4fe9-8bab-0f623137dc0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "cudnn.benchmark = True  # Should make training should go faster for large models\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "id": "95c920d0-5fbf-440e-9d9a-47097f99a16e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Implementation Grad-CAM for ResNet Model"
   ],
   "id": "9f6b0082-543b-48f4-86ea-c8e219fe9d52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = conv3x3(3,64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        # Register hooks for Grad-CAM\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.layer4.register_forward_hook(self._store_activations_hook)\n",
    "        self.layer4.register_backward_hook(self._store_gradients_hook)\n",
    "\n",
    "    def _store_activations_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _store_gradients_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out) \n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ],
   "id": "0477a913-b84d-453b-bdff-d61420b69579"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Implementation Grad-CAM for ResNet18 Model for CIFAR-10"
   ],
   "id": "35d684d4-0fb8-4bee-b105-35ee1e582d24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet18_gradcam_cifar10 = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10.load_state_dict(torch.load(\"checkpoints/resnet18_cifar10.pt\"))\n",
    "resnet18_gradcam_cifar10.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_cutout = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_cutout.load_state_dict(torch.load(\"checkpoints/resnet18_cifar10_cutout.pt\"))\n",
    "resnet18_gradcam_cifar10_cutout.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_da = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_da.load_state_dict(torch.load(\"checkpoints/resnet18_cifar10_da.pt\"))\n",
    "resnet18_gradcam_cifar10_da.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_da_cutout = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_da_cutout.load_state_dict(torch.load(\"checkpoints/resnet18_cifar10_da_cutout.pt\"))\n",
    "resnet18_gradcam_cifar10_da_cutout.eval()"
   ],
   "id": "92eed30e-0052-43e9-b33f-6d4be95b1d95"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to see the result from the testloader of CIFAR-10 dataset"
   ],
   "id": "fb629367-7619-4c10-8b29-73e69a636656"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transform_cifar10 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=1, shuffle=True, num_workers=2)\n"
   ],
   "id": "35ad954b-ba5e-4e61-bccd-985fe2dcdbee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = [\n",
    "    \"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n",
    "    \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"\n",
    "]"
   ],
   "id": "e4ef71b1-4936-4bfa-8bb3-39f7e4da7a50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the testloader\n",
    "images, labels = next(iter(testloader_cifar10))\n",
    "input_tensor = images  # As your batch_size is 1, you will have a single image here\n",
    "\n",
    "# Forward pass\n",
    "resnet18_gradcam_cifar10.zero_grad()\n",
    "output_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_resnet18_gradcam_cifar10 = output_resnet18_gradcam_cifar10.argmax(1)\n",
    "output_resnet18_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_cutout = output_resnet18_gradcam_cifar10_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da = output_resnet18_gradcam_cifar10_da.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da_cutout = output_resnet18_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da = cifar10_classes[target_resnet18_gradcam_cifar10_da.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da_cutout = cifar10_classes[target_resnet18_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_resnet18_gradcam_cifar10 = gradients_resnet18_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_cutout = gradients_resnet18_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da = gradients_resnet18_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da_cutout = gradients_resnet18_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_resnet18_gradcam_cifar10 = (weights_resnet18_gradcam_cifar10 * activations_resnet18_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10 = F.relu(cam_resnet18_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10 = F.interpolate(cam_resnet18_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10 = cam_resnet18_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout = (weights_resnet18_gradcam_cifar10_cutout * activations_resnet18_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.relu(cam_resnet18_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_cutout = cam_resnet18_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da = (weights_resnet18_gradcam_cifar10_da * activations_resnet18_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da = F.relu(cam_resnet18_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da = F.interpolate(cam_resnet18_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da = cam_resnet18_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = (weights_resnet18_gradcam_cifar10_da_cutout * activations_resnet18_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.relu(cam_resnet18_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = cam_resnet18_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_resnet18_gradcam_cifar10 -= cam_resnet18_gradcam_cifar10.min()\n",
    "cam_resnet18_gradcam_cifar10 /= cam_resnet18_gradcam_cifar10.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout -= cam_resnet18_gradcam_cifar10_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_cutout /= cam_resnet18_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da -= cam_resnet18_gradcam_cifar10_da.min()\n",
    "cam_resnet18_gradcam_cifar10_da /= cam_resnet18_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout -= cam_resnet18_gradcam_cifar10_da_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_da_cutout /= cam_resnet18_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "img = images.squeeze().detach().cpu() * std[..., None, None] + mean[..., None, None]\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10 = heatmap_resnet18_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_cutout = heatmap_resnet18_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da = heatmap_resnet18_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da_cutout = heatmap_resnet18_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_resnet18_gradcam_cifar10 / 255)\n",
    "ax[1].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_resnet18_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_resnet18_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_resnet18_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_resnet18_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_resnet18_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "5b1df870-b6a9-4f5d-af41-5e0f6d5352cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "10ff4b67-7f8c-48fe-8da1-bf4e0f08e412"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Implementation Grad-CAM for WideResNet Model"
   ],
   "id": "dda8426f-51d7-492d-8ede-21bdceec857a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WideResNet Code"
   ],
   "id": "dffcdc70-ce26-49d4-bec4-49d436b1bdcd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideResNet\n",
    "\n",
    "# From https://github.com/uoguelph-mlrg/Cutout/blob/master/model/wide_resnet.py\n",
    "\n",
    "class BasicBlockWide(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlockWide, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) // 6\n",
    "        block = BasicBlockWide\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        # Register hooks for Grad-CAM\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.block3.register_forward_hook(self._store_activations_hook)\n",
    "        self.block3.register_backward_hook(self._store_gradients_hook)\n",
    "\n",
    "    def _store_activations_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _store_gradients_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "5666004e-e773-44f1-8e1d-9b339fadbd32"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDSDSDS ::: {.cell .markdown} \\## 4.3.1 Implementation Grad-CAM for WideResNet Model for CIFAR-10 :::"
   ],
   "id": "f100f185-158a-452e-8af4-ff3f1b0488ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wideresnet_gradcam_cifar10 = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10.load_state_dict(torch.load(\"checkpoints/wideresnet_cifar10.pt\"))\n",
    "wideresnet_gradcam_cifar10.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_cutout = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_cutout.load_state_dict(torch.load(\"checkpoints/wideresnet_cifar10_cutout.pt\"))\n",
    "wideresnet_gradcam_cifar10_cutout.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_da = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_da.load_state_dict(torch.load(\"checkpoints/wideresnet_cifar10_da.pt\"))\n",
    "wideresnet_gradcam_cifar10_da.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_da_cutout = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_da_cutout.load_state_dict(torch.load(\"checkpoints/wideresnet_cifar10_da_cutout.pt\"))\n",
    "wideresnet_gradcam_cifar10_da_cutout.eval()"
   ],
   "id": "70b9ee94-d044-4653-b8ff-b17803071168"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to see the result from the testloader of CIFAR-10 dataset"
   ],
   "id": "76e45f77-b3bf-4d2f-a9e0-dd9c7d390fbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "transform_cifar10 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=1, shuffle=True, num_workers=2)\n"
   ],
   "id": "d46ed67a-b3bf-4cd1-af75-f6ff03d4d502"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = [\n",
    "    \"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n",
    "    \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"\n",
    "]"
   ],
   "id": "c686b379-dcd2-471f-81a7-086634c73dc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the testloader\n",
    "images, labels = next(iter(testloader_cifar10))\n",
    "input_tensor = images  # As your batch_size is 1, you will have a single image here\n",
    "\n",
    "# Forward pass\n",
    "wideresnet_gradcam_cifar10.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_wideresnet_gradcam_cifar10 = output_wideresnet_gradcam_cifar10.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_cutout = output_wideresnet_gradcam_cifar10_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da = output_wideresnet_gradcam_cifar10_da.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da_cutout = output_wideresnet_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da = cifar10_classes[target_wideresnet_gradcam_cifar10_da.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da_cutout = cifar10_classes[target_wideresnet_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_wideresnet_gradcam_cifar10 = gradients_wideresnet_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_cutout = gradients_wideresnet_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da = gradients_wideresnet_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da_cutout = gradients_wideresnet_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_wideresnet_gradcam_cifar10 = (weights_wideresnet_gradcam_cifar10 * activations_wideresnet_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10 = F.relu(cam_wideresnet_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 = F.interpolate(cam_wideresnet_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10 = cam_wideresnet_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout = (weights_wideresnet_gradcam_cifar10_cutout * activations_wideresnet_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.relu(cam_wideresnet_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = cam_wideresnet_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da = (weights_wideresnet_gradcam_cifar10_da * activations_wideresnet_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da = F.relu(cam_wideresnet_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da = F.interpolate(cam_wideresnet_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da = cam_wideresnet_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = (weights_wideresnet_gradcam_cifar10_da_cutout * activations_wideresnet_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.relu(cam_wideresnet_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = cam_wideresnet_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 -= cam_wideresnet_gradcam_cifar10.min()\n",
    "cam_wideresnet_gradcam_cifar10 /= cam_wideresnet_gradcam_cifar10.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout -= cam_wideresnet_gradcam_cifar10_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_cutout /= cam_wideresnet_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da -= cam_wideresnet_gradcam_cifar10_da.min()\n",
    "cam_wideresnet_gradcam_cifar10_da /= cam_wideresnet_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout -= cam_wideresnet_gradcam_cifar10_da_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout /= cam_wideresnet_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "img = images.squeeze().detach().cpu() * std[..., None, None] + mean[..., None, None]\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10 = heatmap_wideresnet_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_cutout = heatmap_wideresnet_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da = heatmap_wideresnet_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da_cutout = heatmap_wideresnet_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, constrained_layout=True)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_wideresnet_gradcam_cifar10 / 255)\n",
    "ax[1].set_title('Pred: ' + predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_wideresnet_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_wideresnet_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_wideresnet_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_wideresnet_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_wideresnet_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()"
   ],
   "id": "1be000c5-3c92-4652-adc6-16832d3e6e81"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try to load your image, preprocess it and convert it into a PyTorch tensor. Choose an image that is in the CIFAR-10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks). The preprocessing steps should be the same as the ones you used for training your model. Let’s say you have an image `image.jpg`:"
   ],
   "id": "819aa8a4-249d-4913-8399-93dcc07057b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = \"dog.jpeg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define the transformations: resize, to tensor, normalize (replace the mean and std with values you used for training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # add batch dimension.  C,H,W => B,C,H,W"
   ],
   "id": "89ec519e-b4d6-4572-b793-1ca13250b856"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Grad-CAM"
   ],
   "id": "e3f22980-afe5-4095-aba5-1696483dd99d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "model.zero_grad()\n",
    "output = model(input_tensor)\n",
    "\n",
    "model_co.zero_grad()\n",
    "output_co = model_co(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target = output.argmax(1)\n",
    "output.max().backward()\n",
    "\n",
    "target_co  = output_co .argmax(1)\n",
    "output_co .max().backward()\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients = model.gradients.detach().cpu()\n",
    "activations = model.activations.detach().cpu()\n",
    "\n",
    "gradients_co  = model_co.gradients.detach().cpu()\n",
    "activations_co  = model_co.activations.detach().cpu()\n",
    "\n",
    "# Calculate the weights\n",
    "weights = gradients.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_co = gradients_co.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam = (weights * activations).sum(dim=1, keepdim=True)\n",
    "cam = F.relu(cam)  # apply ReLU to the heatmap\n",
    "cam = F.interpolate(cam, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam = cam.squeeze().numpy()\n",
    "\n",
    "cam_co = (weights_co * activations_co).sum(dim=1, keepdim=True)\n",
    "cam_co = F.relu(cam_co)  # apply ReLU to the heatmap\n",
    "cam_co = F.interpolate(cam_co, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_co = cam_co.squeeze().numpy()\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam -= cam.min()\n",
    "cam /= cam.max()\n",
    "\n",
    "cam_co -= cam_co.min()\n",
    "cam_co /= cam_co.max()"
   ],
   "id": "fd5f14e7-2d62-446c-ad7b-e63687731f4d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the image and the Grad-CAM heatmap"
   ],
   "id": "819f94b1-e831-40ca-b001-a0ea7e40c3c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "\n",
    "heatmap_co = cv2.applyColorMap(np.uint8(255 * cam_co), cv2.COLORMAP_JET)\n",
    "heatmap_co = cv2.cvtColor(heatmap_co, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_co = heatmap_co * 0.4 + img\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(superimposed_img / 255)\n",
    "ax[1].set_title('Grad-CAM')\n",
    "ax[1].axis(\"off\")\n",
    "ax[2].imshow(superimposed_img_co / 255)\n",
    "ax[2].set_title('Grad-CAM with Cutout')\n",
    "ax[2].axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "361711cf-7ce7-4434-99a4-e2cbe23cbc56"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
