{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ],
   "id": "b17aedb0-b5f7-4843-a65b-0226e8a016ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: This notebook has been developed and tested for pytorch \n",
    "print(torch. __version__)"
   ],
   "id": "b8badfba-26cc-47e8-bbb6-b73a3b0be754"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutout data augmentation\n",
    "\n",
    "In this notebook, we will reproduce the results of the paper\n",
    "\n",
    "> DeVries, T. and Taylor, G.W., 2017. Improved regularization of convolutional neural networks with Cutout. arXiv preprint [arXiv:1708.04552](https://arxiv.org/abs/1708.04552).\n",
    "\n",
    "We will use the author’s implementation of their technique, from <https://github.com/uoguelph-mlrg/Cutout>, which is licensed under an Educational Community License version 2.0."
   ],
   "id": "558901ba-268e-4a67-9031-c76f01fedbaf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning outcomes\n",
    "\n",
    "After working through this notebook, you should be able to:\n",
    "\n",
    "-   Describe how Cutout works as a regularization technique,\n",
    "-   Enumerate specific claims (both quantitative claims, qualitative claims, and claims about the underlying mechanism behind a result) from the Cutout paper,\n",
    "-   Execute experiments (following the given procedure) to try and validate each claim about Cutout data augmentation,\n",
    "-   Evaluate whether your own result matches quantitative claims in the Cutout paper (i.e. whether it is within the confidence intervals for each reported numeric result),\n",
    "-   Evaluate whether your own result validates qualitative claims in the Cutout paper,\n",
    "-   Evaluate whether your own results support the author’s claim about the underlying mechanism behind the result."
   ],
   "id": "aa255be3-21d8-468b-9f42-f24bd7bbc0f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections that follow, we will identify and evaluate claims from the original Cutout paper:\n",
    "\n",
    "1.  Cutout improves the robustness and overall performance of convolutional neural networks.\n",
    "2.  Cutout can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance.\n",
    "3.  Cutout aimed to remove maximally activated features in order to encourage the network to consider less prominent features"
   ],
   "id": "34b6a431-373c-474d-bfb2-9340c25025fc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cutout as a regularization technique\n",
    "\n",
    "This Jupyter notebook is designed to illustrate the implementation and usage of the Cutout data augmentation technique in deep learning, specifically in the context of Convolutional Neural Networks (CNNs)."
   ],
   "id": "25fc46cb-647f-4185-866c-a913146af65e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutout is a regularization and data augmentation technique for convolutional neural networks (CNNs). It involves randomly masking out square regions of input during training. This helps to improve the robustness and overall performance of CNNs by encouraging the network to better utilize the full context of the image, rather than relying on the presence of a small set of specific visual features.\n",
    "\n",
    "Cutout is computationally efficient as it can be applied during data loading in parallel with the main training task. It can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance.\n",
    "\n",
    "The technique has been evaluated with state-of-the-art architectures on popular image recognition datasets such as CIFAR-10, CIFAR-100, and SVHN, often achieving state-of-the-art or near state-of-the-art results."
   ],
   "id": "46fb6cc8-1384-41c8-b191-0b13d161fca9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Cutout"
   ],
   "id": "f92d96cd-ea33-459c-8908-d9e8ae50b7a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomCrop, ColorJitter\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "372b9aac-c877-435f-88a4-f30bb398407b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, we will see how Cutout works when applied to a sample image.\n",
    "\n",
    "<!-- To do: explain the code with reference to section 3.2. Implementation Details -->\n",
    "\n",
    "In the code provided above, we see a Python class named Cutout defined. This class is designed to apply the Cutout data augmentation technique to an image. Below is an explanation of the class and its methods:\n",
    "\n",
    "-   The Cutout class is initialized with two parameters:\n",
    "\n",
    "    -   `n_holes`: the number of patches to cut out of each image.\n",
    "    -   `length`: the length (in pixels) of each square patch.\n",
    "\n",
    "-   The `__call__` method implements the Cutout technique. This method takes as input a tensor `img` representing an image, and returns the same image with `n_holes` number of patches of dimension `length` x `length` cut out of it.\n",
    "\n",
    "Here’s a step-by-step explanation of what’s happening inside the `__call__` method:\n",
    "\n",
    "1.  The method first retrieves the height h and width w of the input image.\n",
    "\n",
    "2.  A mask is then initialized as a 2D numpy array of ones with the same dimensions as the input image.\n",
    "\n",
    "3.  The method then enters a loop which runs for n_holes iterations. In each iteration:\n",
    "\n",
    "    -   A pair of coordinates y and x are randomly selected within the height and width of the image.\n",
    "\n",
    "    -   The method then calculates the coordinates of a square patch around the (y, x) coordinate. The patch has a length of length pixels, and the method ensures that the patch doesn’t fall outside the image by using the np.clip function.\n",
    "\n",
    "    -   The corresponding area in the mask is set to zero.\n",
    "\n",
    "4.  The mask is then converted to a PyTorch tensor and expanded to the same number of channels as the input image.\n",
    "\n",
    "5.  Finally, the method applies the mask to the input image, effectively setting the pixels in the masked regions to zero, and returns the result.\n",
    "\n",
    "Remember to import necessary libraries like numpy (np) and PyTorch (torch) before running this class definition. The class Cutout can then be used as part of your data augmentation pipeline when training your models.\n",
    "\n",
    "The Cutout code we are using comes from this specific file in the original GitHub repository: \\[https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\\]."
   ],
   "id": "8da76a87-4b18-4e53-ab6b-69716655489c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: link to the file in the original repo that this comes from\n",
    "# Source Code from https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ],
   "id": "2ee75554-2ecc-4af9-b4a3-a0e22a380b21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how it works, in the following cell, you will upload an image of your choice to this workspace. To prevent any distortion due to resizing, it is advised to use an image that is approximately square in shape, as we will be resizing the image to a square format (100x100 pixels) later on:\n",
    "\n",
    "<!-- to do - add instructions for uploading image on Colab, or on Chameleon -->\n",
    "\n",
    "To see how Cutout works, let’s upload an image and apply Cutout to it. Follow these steps to upload an image in this Google Colab notebook:\n",
    "\n",
    "1.  Click on the folder icon in the left sidebar to open the ‘Files’ tab.\n",
    "2.  Click the ‘Upload to session storage’ button (the icon looks like a file with an up arrow).\n",
    "3.  Select the image file from your local machine that you want to upload.\n",
    "4.  Wait for the upload to finish. The uploaded file should now appear in the ‘Files’ tab. After the image is uploaded, we can use Python code to load it into our notebook and apply the Cutout augmentation\n",
    "\n",
    "If you are using Chameleon, here are the steps: <!-- to do - add instructions for uploading image on Chameleon -->\n",
    "\n",
    "1.  Click on the upload icon in the left sidebar.\n",
    "2.  Select the image file from your local machine that you want to upload.\n",
    "3.  Wait for the upload to finish. The uploaded file should now appear in the ‘Files’ tab. After the image is uploaded, we can use Python code to load it into our notebook and apply the Cutout augmentation to the image."
   ],
   "id": "bc9fe3f3-3481-4b9f-b67a-ddb6285ba782"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace 'sample.png' with the filename of your own image. \n",
    "# If your image is inside a directory, include the directory's name in the path.\n",
    "img = Image.open('./sample.png')\n",
    "\n",
    "# Resize the image to 100x100\n",
    "img = img.resize((100, 100))"
   ],
   "id": "979832b9-be2b-420d-ae9e-d8fab2dc54f1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the following cell will display your image directly, without any data augmentation:"
   ],
   "id": "1bee40d8-edc5-4a6a-abf4-ed17a6cb6ac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a PyTorch tensor\n",
    "img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img_tensor.permute(1, 2, 0))\n",
    "plt.show()"
   ],
   "id": "4ee48d6b-8a2f-4cd3-a42a-8711f3110d39"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the next cell will display your image with Cutout applied:"
   ],
   "id": "2f437244-69aa-4e88-8de5-0c7683945b98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cutout object\n",
    "cutout_obj = Cutout(n_holes=1, length=50)\n",
    "\n",
    "# Apply Cutout to the image\n",
    "img_tensor_Cutout = cutout_obj(img_tensor)\n",
    "\n",
    "# Convert the tensor back to an image for visualization\n",
    "img_Cutout = transforms.ToPILImage()(img_tensor_Cutout)\n",
    "\n",
    "# Display the image with Cutout applied\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img_tensor_Cutout.permute(1, 2, 0))\n",
    "plt.show()"
   ],
   "id": "b9b462c2-dd6d-427e-8fae-ce88a29f81f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "\n",
    "-   You can re-run the cell above several times to see how the occlusion is randomly placed in a different position each time.\n",
    "-   You can try changing the `length` parameter in the cell above, and re-running, to see how the size of the occlusion can change.\n",
    "-   You can try changing the `n_holes` parameter in the cell above, and re-running, to see how the number of occlusions can change."
   ],
   "id": "998dcaab-6461-4b44-8dc9-af5f110d43b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #TODO: Set the number of patches (\"holes\") to cut out of the image.\n",
    "n_holes = \n",
    "\n",
    "#TODO: Set the size (length of a side) of each patch.\n",
    "length = \n",
    "\n",
    "\n",
    "# Create a Cutout object\n",
    "Cutout = Cutout(n_holes, length)\n",
    "\n",
    "# Apply Cutout to the image\n",
    "img_tensor_Cutout = Cutout(img_tensor)\n",
    "\n",
    "# Convert the tensor back to an image for visualization\n",
    "img_Cutout = transforms.ToPILImage()(img_tensor_Cutout)\n",
    "\n",
    "# Display the image with Cutout applied\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img_tensor_Cutout.permute(1, 2, 0))\n",
    "plt.show()"
   ],
   "id": "5267a615-1e6b-4a51-845d-9176d8feae83"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutout was introduced as an alternative to two closely related techniques:\n",
    "\n",
    "-   Data Augmentation for Images: Data augmentation is a strategy used to increase the diversity of the data available for training models, without actually collecting new data. For image data, this could include operations like rotation, scaling, cropping, flipping, and adding noise. The goal is to make the model more robust by allowing it to see more variations of the data.\n",
    "\n",
    "-   Dropout in Convolutional Neural Networks: Dropout is a regularization technique for reducing overfitting in neural networks. During training, some number of layer outputs are randomly ignored or “dropped out”. This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, dropout simulates ensembling a large number of neural networks with different architectures, which makes the model more robust.\n",
    "\n",
    "<!-- to do - expand on these -->"
   ],
   "id": "bebf9225-5cc2-4d21-8e5a-f98a7fdaced3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code snippet, we demonstrate some “standard” data augmentation techniques commonly used in image preprocessing. These techniques include random horizontal flipping, random cropping, and color jittering (random variation in brightness, contrast, saturation, and hue). The augmented image is then displayed alongside the original image for comparison."
   ],
   "id": "a7a423fa-d0a3-4105-b616-e114ddbdaacc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do - show the same image with \"standard\" data augmentation techniques\n",
    "# discussed in the related work section of the paper\n",
    "\n",
    "# Define standard data augmentation techniques\n",
    "transforms_data_augmentation = transforms.Compose([\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomCrop(size=(100, 100), padding=4),  # assuming input image is size 100x100\n",
    "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "])\n",
    "\n",
    "# Apply transformations to the image\n",
    "augmented_img = transforms_data_augmentation(img)\n",
    "\n",
    "# Display the original and augmented image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(augmented_img)\n",
    "ax[1].set_title('Augmented Image')\n",
    "plt.show()\n"
   ],
   "id": "1678ef96-e990-41b1-a67a-0bce1e327318"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. ResNet"
   ],
   "id": "98a7d0f5-3ad3-4d45-a0c1-6503fa5a2017"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for faster training, use Runtime \\> Change Runtime Type to run this notebook on a GPU."
   ],
   "id": "6daea56b-e369-45f5-a339-c190179ca2cf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Cutout paper, the authors claim that:\n",
    "\n",
    "1.  Cutout improves the robustness and overall performance of convolutional neural networks.\n",
    "2.  Cutout can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance.\n",
    "\n",
    "In this section, we will evaluate these claims using a ResNet model. For the ResNet model, the specific quantitative claims are given in the following table:\n",
    "\n",
    "Test error (%, flip/translation augmentation, mean/std normalization, mean of 5 runs) and “+” indicates standard data augmentation (mirror + crop)\n",
    "\n",
    "| **Network**       | **CIFAR-10** | **CIFAR-10+** | **CIFAR-100** | **CIFAR-100+** |\n",
    "|-------------|--------------|----------------|--------------|----------------|\n",
    "| ResNet18          | 10.63        | 4.72          | 36.68         | 22.46          |\n",
    "| ResNet18 + cutout | 9.31         | 3.99          | 34.98         | 21.96          |\n",
    "\n",
    "The provided table displays the results of experiments conducted on the CIFAR-10 and CIFAR-100 datasets using the ResNet18 architecture, revealing the impact of standard and cutout data augmentation techniques. The “CIFAR-10+” and “CIFAR-100+” labels indicate the use of standard data augmentation, which involves mirror and crop techniques.\n",
    "\n",
    "With the use of standard data augmentation on CIFAR-10, the ResNet18 model’s test error is significantly reduced from 14.04% to 5.72%. Further enhancement is achieved when cutout augmentation is applied, bringing down the error to 4.86%. A similar pattern is observed in the case of the CIFAR-100 dataset, where standard augmentation reduces the ResNet18 model’s test error from 40.13% to 24.36%. Upon applying cutout augmentation, a slight further reduction in error to 23.9% is noted.\n",
    "\n",
    "These findings emphasize the efficacy of both standard and cutout data augmentation techniques in enhancing the model’s performance, evidenced by the reduction in test error rates on both CIFAR-10 and CIFAR-100 datasets. The results also highlight that the impact of data augmentation can vary based on the complexity of the dataset, illustrated by the differing rates of error reduction between CIFAR-10 and CIFAR-100."
   ],
   "id": "8e326a09-12e1-4ac0-aca1-bb592d3030cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ],
   "id": "9d6e63c2-092d-468c-9c08-9a6ead772be2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "id": "62263b75-ce97-4048-a089-38770dc05132"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Cuda GPU availability and set seed number"
   ],
   "id": "c6616164-b45f-4ba4-8155-067c2d66baed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "cudnn.benchmark = True  # Should make training should go faster for large models\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "id": "cee3681f-b800-4af9-b788-14c410ad02f4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, here’s a step-by-step how to connect with your google drive:\n",
    "\n",
    "1.  On the left sidebar of the Colab notebook interface, you will see a folder icon with the Google Drive logo. Click on this folder icon to open the file explorer.\n",
    "\n",
    "2.  If you haven’t connected your Google Drive to Colab yet, it will prompt you to do so. Click the “Mount Drive” button to connect your Google Drive to Colab.\n",
    "\n",
    "3.  Once your Google Drive is mounted, you can use the file explorer to navigate to the file you want to open. Click on the folders to explore the contents of your Google Drive.\n",
    "\n",
    "4.  When you find the file you want to open, click the three dots next to the name of the file in the file explorer. From the options that appear, choose “Copy path.” This action will copy the full path of the file to your clipboard. Paste the copy path into the ‘current_path’ below."
   ],
   "id": "b4e15b35-a068-4fba-982f-a941485ea96b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path =\"./\""
   ],
   "id": "9f7305bb-d07a-436e-b186-ba7752c0c2e6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is used for creating a directory named ‘checkpoints’. This directory will be used to store the weights of our models, which are crucial for both preserving our progress during model training and for future use of the trained models.\n",
    "\n",
    "Creating such a directory and regularly saving model weights is a good practice in machine learning, as it ensures that you can resume your work from where you left off, should the training process be interrupted."
   ],
   "id": "a07dd887-8f1d-4974-b393-bda0f685ebf9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file names 'checkpoints' to save the weight of the models\n",
    "if not os.path.exists(current_path + 'checkpoints'):\n",
    "    os.makedirs(current_path + 'checkpoints')"
   ],
   "id": "3f679c34-5b6d-4bf6-b206-89203ed000cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implementation Code"
   ],
   "id": "1c8f9681-17f7-4d67-b4cf-908363dd71fb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 ResNet Code"
   ],
   "id": "2dcce924-2b8c-47e1-8e9f-263d5437c548"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "# From https://github.com/uoguelph-mlrg/Cutout/blob/master/model/resnet.py\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = conv3x3(3,64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)"
   ],
   "id": "44f3be15-f43d-4351-81b1-83adf37febe4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Model Evaluate Test Code\n",
    "\n",
    "This function evaluates the performance of the model on a given data loader (loader). It sets the model to evaluation mode (eval), calculates the accuracy on the dataset, and returns the validation accuracy. It then switches the model back to training mode (train) before returning the validation accuracy."
   ],
   "id": "3fcb177c-cf76-40ff-8733-9ec91ca78a91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, cnn):\n",
    "    cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    for images, labels in loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = cnn(images)\n",
    "\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    cnn.train()\n",
    "    return val_acc"
   ],
   "id": "b966b886-82b2-4e9c-b45f-eceb00dfa4e6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training ResNet-18 in CIFAR-10"
   ],
   "id": "08b4ac03-c0e0-4830-a959-f655f81d4ee8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Training ResNet-18 in CF10 without Cutout"
   ],
   "id": "cb4da35e-1a09-44f7-a376-d90493dae666"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "01718fb5-8d87-4db6-a331-ce343d462c85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10 = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar10.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "f62e6f52-04fe-4077-bf18-69f27f53ea5f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "d3fa4217-29dc-46da-b46c-85c34c8f4d48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "c94ee09e-c29f-4e5a-b774-411537f0f0f1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "55e60911-5d99-4c95-8e90-61e9e4971bd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10 = 128\n",
    "train_loader_cifar10 = torch.utils.data.DataLoader(dataset=train_dataset_cifar10,\n",
    "                                           batch_size=batch_size_cifar10,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "2a84fe91-0e66-45ac-8b9d-0b5acc0204c1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "320439f2-deeb-434a-8874-142051bb6cf9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "3fba9c34-145e-40aa-825d-e590f6258b43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar10 = \"resnet18_cifar10\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "resnet18_cifar10 = ResNet18(num_classes=num_classes_cifar10)\n",
    "\n",
    "\n",
    "resnet18_cifar10 = resnet18_cifar10.cuda()\n",
    "learning_rate_resnet18_cifar10 = 0.1\n",
    "criterion_resnet18_cifar10 = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar10 = torch.optim.SGD(resnet18_cifar10.parameters(), lr=learning_rate_resnet18_cifar10,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar10 = MultiStepLR(cnn_optimizer_resnet18_cifar10, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "d9f93a5f-e97d-491e-9037-8134fb58c44c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 withuout Cutout"
   ],
   "id": "437f650e-7810-4b77-b71b-0e9c0106ee7b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "581bd64a-06cc-4497-ae6b-cae7cebcaf56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar10.zero_grad()\n",
    "        pred = resnet18_cifar10(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar10(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar10.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_accr_resnet18_cifar10 = test(test_loader_cifar10, resnet18_cifar10)\n",
    "    tqdm.write('test_acc: %.3f' % (test_accr_resnet18_cifar10))\n",
    "\n",
    "    scheduler_resnet18_cifar10.step()    \n",
    "\n",
    "    \n",
    "torch.save(resnet18_cifar10.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar10 + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar10 = (1 - test(test_loader_cifar10, resnet18_cifar10))*100\n",
    "print('Final Result ResNet-18 without Cutout for Test CIFAR-10 Dataset: %.3f' % (final_test_acc_resnet18_cifar10))"
   ],
   "id": "128a17be-2ffc-42ea-a792-2c38f4060593"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Training ResNet-18 in CF10 with Cutout"
   ],
   "id": "5fdbdfb6-0183-4d15-8d45-c16b491de5eb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutout Code"
   ],
   "id": "e4d8e919-91ff-4689-87b0-ce7c45f5fc9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: link to the file in the original repo that this comes from\n",
    "# Source Code from https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ],
   "id": "92a41dd6-ea7c-4854-a687-75120cf5e7f6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "0b2a8fa4-5be6-477f-bf33-a7f13259c584"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_cutout = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar10_cutout.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_cutout.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar10 = 1\n",
    "length_cifar10 = 16\n",
    "train_transform_cifar10_cutout.transforms.append(Cutout(n_holes=n_holes_cifar10, length=length_cifar10))\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "50bf5ade-f089-4f01-8e81-e6d849126dc4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "5dbae2b3-0132-4810-9b3e-983181133a51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_cutout = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_cutout,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "6bfe6c18-5cfd-4f64-bfb0-f09ef0ead8f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "40f176fb-b8a7-4905-9d5f-a3043ab05fa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_cutout = 128\n",
    "train_loader_cifar10_cutout = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_cutout,\n",
    "                                           batch_size=batch_size_cifar10_cutout,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_cutout,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "e6a1da6d-5913-4d53-8089-af15d0ba4fc1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "f6b49be1-230e-497b-85f4-dec0d884a372"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "3c0fe59d-5e16-40e6-8303-a3e986f6225c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar10_cutout = \"resnet18_cifar10_cutout\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "resnet18_cifar10_cutout = ResNet18(num_classes=num_classes_cifar10)\n",
    "\n",
    "\n",
    "resnet18_cifar10_cutout = resnet18_cifar10_cutout.cuda()\n",
    "learning_rate_resnet18_cifar10_cutout = 0.1\n",
    "criterion_resnet18_cifar10_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar10_cutout = torch.optim.SGD(resnet18_cifar10_cutout.parameters(), lr=learning_rate_resnet18_cifar10_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar10_cutout = MultiStepLR(cnn_optimizer_resnet18_cifar10_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "1d861ed5-cd8a-4865-a86f-2ae6574819fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Cutout"
   ],
   "id": "2bcbc250-592f-4168-9f0a-17d59d9636d0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "5fec70ae-a05b-49ba-acaf-00e72c5b06be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_cutout)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar10_cutout.zero_grad()\n",
    "        pred = resnet18_cifar10_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar10_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar10_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar10 = test(test_loader_cifar10,resnet18_cifar10_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar10))\n",
    "    scheduler_resnet18_cifar10_cutout.step()     \n",
    "torch.save(resnet18_cifar10_cutout.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar10_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar10_cutout = (1 - test(test_loader_cifar10,resnet18_cifar10_cutout))*100\n",
    "print('Final Result ResNet-18 using Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_cutout))"
   ],
   "id": "fa7be0cb-7751-4fb2-bf78-aacbe7fd2df5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Training ResNet-18 in CF10 with Data Augmentation"
   ],
   "id": "4d57ea60-42dc-4bb5-bb91-8eacd6ae6d63"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "25124262-a341-43f0-9715-38f653d30a5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_da = transforms.Compose([])\n",
    "train_transform_cifar10_da.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar10_da.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar10_da.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_da.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "6ebf4954-a108-4774-abf4-a333b13fc04d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "52641fba-535a-4306-b65a-921243fcbdc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_da = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_da,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "78cccada-80a8-43b4-90e6-68a4118d7441"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "4ee6b3f0-ade3-4fd2-a802-9b1059a9a338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_da = 128\n",
    "train_loader_cifar10_da = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_da,\n",
    "                                           batch_size=batch_size_cifar10_da,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_da,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "f8e59770-4b2c-4330-9e45-6e4204666a29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "8751dc2b-a334-4d7a-bedb-774b4640eabd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "9d4aa700-cd20-486d-8c0f-5c42c9d83503"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar10_da = \"resnet18_cifar10_da\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "resnet18_cifar10_da = ResNet18(num_classes=num_classes_cifar10)\n",
    "\n",
    "\n",
    "resnet18_cifar10_da = resnet18_cifar10_da.cuda()\n",
    "learning_rate_resnet18_cifar10_da = 0.1\n",
    "criterion_resnet18_cifar10_da = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar10_da = torch.optim.SGD(resnet18_cifar10_da.parameters(), lr=learning_rate_resnet18_cifar10_da,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar10_da = MultiStepLR(cnn_optimizer_resnet18_cifar10_da, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "f056a3f7-1ef6-44f0-8aed-45fc4c54acef"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Data Augmentation"
   ],
   "id": "388341ce-eea6-44c2-8ef9-63eb11c62a5a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "8fb49c8e-3324-4e47-a556-54b8691bd795"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_da)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar10_da.zero_grad()\n",
    "        pred = resnet18_cifar10_da(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar10_da(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar10_da.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_resnet18_cifar10_da = test(test_loader_cifar10,resnet18_cifar10_da)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_resnet18_cifar10_da))\n",
    "    scheduler_resnet18_cifar10_da.step()     \n",
    "torch.save(resnet18_cifar10_da.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar10_da + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar10_da = (1 - test(test_loader_cifar10,resnet18_cifar10_da))*100\n",
    "print('Final Result ResNet-18 using Data Augmentation for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_da))"
   ],
   "id": "47dc3764-ad5b-4b4b-9e90-f47add4b098b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Training ResNet-18 in CF10 with Data Augmentation with Cutout"
   ],
   "id": "3788be8b-ad29-4076-9ca7-186b570c48e6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "01ca1575-d85d-4261-acdd-b1e5a05e9037"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_da_co = transforms.Compose([])\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_da_co.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar10_da_co = 1\n",
    "length_cifar10_da_co = 16\n",
    "train_transform_cifar10_da_co.transforms.append(Cutout(n_holes=n_holes_cifar10_da_co, length=length_cifar10_da_co))\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "ceef26a7-cb18-4469-952f-2aaa1cadca13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "5ed4a992-d3b3-42b9-9a16-0156254dacee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_da_co = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_da_co,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "af7ec2fc-9b1d-4051-a958-dbe67a3f5364"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "f4f94f3b-3518-495c-ba46-8b68ca69ced8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_da_co = 128\n",
    "train_loader_cifar10_da_co = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_da_co,\n",
    "                                           batch_size=batch_size_cifar10_da_co,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_da_co,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "1d3a9309-ce42-4790-93e8-4c7df9cecec2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "eed1ce7d-ab47-4698-8e98-92d90dc1105d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "c1974ab2-4100-4dfb-9dae-7724fc373c1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar10_da_cutout = \"resnet18_cifar10_da_cutout\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "resnet18_cifar10_da_cutout = ResNet18(num_classes=num_classes_cifar10)\n",
    "\n",
    "\n",
    "resnet18_cifar10_da_cutout = resnet18_cifar10_da_cutout.cuda()\n",
    "learning_rate_cifar10_da_cutout = 0.1\n",
    "criterion_cifar10_da_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_cifar10_da_cutout = torch.optim.SGD(resnet18_cifar10_da_cutout.parameters(), lr=learning_rate_cifar10_da_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_cifar10_da_cutout = MultiStepLR(cnn_optimizer_cifar10_da_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "a2720241-3dab-4de6-b9da-75f1a2aa05f2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Cutout"
   ],
   "id": "78905bbf-f60d-4df1-9ccd-11112518a19a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "dcde2499-e752-460e-bfb9-bc2ce0c101e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_da_co)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar10_da_cutout.zero_grad()\n",
    "        pred = resnet18_cifar10_da_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_cifar10_da_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_cifar10_da_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar10_da_cutout = test(test_loader_cifar10,resnet18_cifar10_da_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar10_da_cutout))\n",
    "    scheduler_cifar10_da_cutout.step()     \n",
    "torch.save(resnet18_cifar10_da_cutout.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar10_da_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar10_da_cutout = (1 - test(test_loader_cifar10,resnet18_cifar10_da_cutout))*100\n",
    "print('Final Result ResNet-18 using Data Augmentation and  Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_da_cutout))"
   ],
   "id": "fd87015a-03de-44ed-bd2b-43ca9fd30688"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Result ResNet-18 without Cutout for Test CIFAR-10 Dataset: %.3f' % (final_test_acc_resnet18_cifar10))\n",
    "print('Final Result ResNet-18 using Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_cutout))\n",
    "print('Final Result ResNet-18 using Data Augmentation for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_da))\n",
    "print('Final Result ResNet-18 using Data Augmentation and  Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar10_da_cutout))"
   ],
   "id": "3b37f083-eaf4-4556-98d9-f0aee13bcbc8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training ResNet-18 in CIFAR-100"
   ],
   "id": "242f066e-903f-4646-977c-5a819853ae8d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Training ResNet-18 in CF100 without Cutout"
   ],
   "id": "af60c933-55df-4571-b5fd-232a3f308822"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "0d45a488-4107-4e6f-8e25-09b55d9264e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100 = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar100.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "324aa134-e557-4eee-9541-ad0d2f78bbb9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "a46804d7-ba44-47d5-bab2-d39481aea30d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "454f1583-1204-4b61-9e32-4c924027f6cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "bf65b15b-553a-4605-bf91-1eded91b6ab5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100 = 128\n",
    "train_loader_cifar100 = torch.utils.data.DataLoader(dataset=train_dataset_cifar100,\n",
    "                                           batch_size=batch_size_cifar100,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "2398da00-cf45-42c4-9447-f97762f91812"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "94b4a54a-50d5-497d-a270-a35e90df52ee"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "b59655f2-7c01-48f4-a2e0-f1c1a912f7c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar100 = \"resnet18_cifar100\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "resnet18_cifar100 = ResNet18(num_classes=num_classes_cifar100)\n",
    "\n",
    "\n",
    "resnet18_cifar100 = resnet18_cifar100.cuda()\n",
    "learning_rate_resnet18_cifar100 = 0.1\n",
    "criterion_resnet18_cifar100 = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar100 = torch.optim.SGD(resnet18_cifar100.parameters(), lr=learning_rate_resnet18_cifar100,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar100 = MultiStepLR(cnn_optimizer_resnet18_cifar100, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "bb8e4a63-da95-4153-bc99-ed15a2f34157"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 withuout Cutout"
   ],
   "id": "f7260cb0-903a-49d0-be22-a9b41bae1e70"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "f21bef22-3ea9-4e38-98fc-35d4fc05f099"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar100.zero_grad()\n",
    "        pred = resnet18_cifar100(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar100(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar100.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_accr_resnet18_cifar100 = test(test_loader_cifar100, resnet18_cifar100)\n",
    "    tqdm.write('test_acc: %.3f' % (test_accr_resnet18_cifar100))\n",
    "\n",
    "    scheduler_resnet18_cifar100.step()   \n",
    "    \n",
    "torch.save(resnet18_cifar100.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar100 + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar100 = (1 - test(test_loader_cifar100, resnet18_cifar100))*100\n",
    "print('Final Result ResNet-18 without Cutout for Test CIFAR-100 Dataset: %.3f' % (final_test_acc_resnet18_cifar100))"
   ],
   "id": "2a29aade-7bc4-491d-82e8-bb1bcd1602da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Training ResNet-18 in CF100 with Cutout"
   ],
   "id": "d9d3fc45-2f72-43af-9b62-b9c82b6c32df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "1c157ec8-a978-454f-bbf6-d80010f16c54"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_cutout = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar100_cutout.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_cutout.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar100 = 1\n",
    "length_cifar100 = 8\n",
    "train_transform_cifar100_cutout.transforms.append(Cutout(n_holes=n_holes_cifar100, length=length_cifar100))\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "ffe809bc-5582-43cb-91a0-b97143caa48a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-0"
   ],
   "id": "5c2d5242-8b86-424b-bf4e-f53bb0a0b05d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_cutout = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_cutout,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "5b177a07-210d-4e4f-b1d9-c81569fb1fe4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "695eb50b-3be7-4c13-a16e-7383dd008961"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_cutout = 128\n",
    "train_loader_cifar100_cutout = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_cutout,\n",
    "                                           batch_size=batch_size_cifar100_cutout,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_cutout,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "9b1867ff-93eb-492c-a7dc-fe448bb0b98e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "06232ed8-5b44-4a0a-9a7f-c18832f0b0ff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "2f4f7b2c-0c54-4130-a002-f7cafb8e0f0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar100_cutout = \"resnet18_cifar100_cutout\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "resnet18_cifar100_cutout = ResNet18(num_classes=num_classes_cifar100)\n",
    "\n",
    "\n",
    "resnet18_cifar100_cutout = resnet18_cifar100_cutout.cuda()\n",
    "learning_rate_resnet18_cifar100_cutout = 0.1\n",
    "criterion_resnet18_cifar100_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar100_cutout = torch.optim.SGD(resnet18_cifar100_cutout.parameters(), lr=learning_rate_resnet18_cifar100_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar100_cutout = MultiStepLR(cnn_optimizer_resnet18_cifar100_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "88cbba47-9236-465b-ac3a-9eae5d9e5a43"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Cutout"
   ],
   "id": "6baa28a8-d138-412b-bda6-31c2965f50f0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "6b86213b-2b86-42ef-b618-083980eb2479"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_cutout)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar100_cutout.zero_grad()\n",
    "        pred = resnet18_cifar100_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar100_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar100_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar100 = test(test_loader_cifar100,resnet18_cifar100_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar100))\n",
    "    scheduler_resnet18_cifar100_cutout.step()     \n",
    "torch.save(resnet18_cifar100_cutout.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar100_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar100_cutout = (1 - test(test_loader_cifar100,resnet18_cifar100_cutout))*100\n",
    "print('Final Result ResNet-18 using Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_cutout))"
   ],
   "id": "340988bc-6d9d-4cdb-8208-f5337bdbf2ca"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Training ResNet-18 in CF100 with Data Augmentation"
   ],
   "id": "e88b4602-682b-448a-b94a-6520e1693996"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "d44fb67f-42a8-489e-b228-5aecd5fa7c57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_da = transforms.Compose([])\n",
    "train_transform_cifar100_da.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar100_da.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar100_da.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_da.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "284fe2e5-152b-4272-b347-02325101c38b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "ca431bbe-78e9-4719-a012-f2b068f650f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_da = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_da,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "db303977-4d38-441c-b2a4-13c8bcbe2991"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "aaaa0d61-bcbf-4905-82be-9e3219c7b6bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_da = 128\n",
    "train_loader_cifar100_da = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_da,\n",
    "                                           batch_size=batch_size_cifar100_da,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_da,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "2f0723b6-476a-4941-a823-3c2850bd4d9f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "8c74b809-3181-465f-ad6a-192ea80c3ff0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "4ac1ea0d-04b0-49d3-b7df-e68b8980feff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar100_da = \"resnet18_cifar100_da\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "resnet18_cifar100_da = ResNet18(num_classes=num_classes_cifar100)\n",
    "\n",
    "\n",
    "resnet18_cifar100_da = resnet18_cifar100_da.cuda()\n",
    "learning_rate_resnet18_cifar100_da = 0.1\n",
    "criterion_resnet18_cifar100_da = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_resnet18_cifar100_da = torch.optim.SGD(resnet18_cifar100_da.parameters(), lr=learning_rate_resnet18_cifar100_da,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_resnet18_cifar100_da = MultiStepLR(cnn_optimizer_resnet18_cifar100_da, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "f536ded2-2e56-400c-9b82-1a27caddd833"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Data Augmentation"
   ],
   "id": "02613afe-232e-40d6-bfb6-b61bd8ce4cf4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "f3e22b96-271a-424c-ba2c-8f9c68a6e6b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_da)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar100_da.zero_grad()\n",
    "        pred = resnet18_cifar100_da(images)\n",
    "\n",
    "        xentropy_loss = criterion_resnet18_cifar100_da(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_resnet18_cifar100_da.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_resnet18_cifar100_da = test(test_loader_cifar100,resnet18_cifar100_da)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_resnet18_cifar100_da))\n",
    "    scheduler_resnet18_cifar100_da.step()     \n",
    "torch.save(resnet18_cifar100_da.state_dict(), current_path + 'checkpoints/' + file_name_resnet18_cifar100_da + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar100_da = (1 - test(test_loader_cifar100,resnet18_cifar100_da))*100\n",
    "print('Final Result ResNet-18 using Data Augmentation for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_da))"
   ],
   "id": "663856df-d87c-4502-a236-6b3d9ab7a3d6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Training ResNet-18 in CF100 with Data Augmentation with Cutout"
   ],
   "id": "1141a6a5-621f-4090-85be-b0e0dfe9697d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "3e9009f5-e1c1-4449-a87b-9cc26c48027c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_da_co = transforms.Compose([])\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_da_co.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar100_da_co = 1\n",
    "length_cifar100_da_co = 8\n",
    "train_transform_cifar100_da_co.transforms.append(Cutout(n_holes=n_holes_cifar100_da_co, length=length_cifar100_da_co))\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "bfe59fbc-0946-42c4-acb5-18acc072ea0b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "c50e355d-7583-4800-a674-21c9be854985"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_da_co = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_da_co,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "5cde89d3-d608-46e5-ac2b-48573b6a3e83"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "3dac9671-249b-4d02-9612-4918774755b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_da_co = 128\n",
    "train_loader_cifar100_da_co = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_da_co,\n",
    "                                           batch_size=batch_size_cifar100_da_co,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_da_co,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "a06636d3-daae-4f33-a451-9be59615bd7d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "ae99a5d8-6305-4a28-886f-a2eb9836806f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "8eef3e94-1440-40d1-96b0-1ac1458bf65e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_resnet18_cifar100_da_cutout = \"resnet18_cifar100_da_cutout\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "resnet18_cifar100_da_cutout = ResNet18(num_classes=num_classes_cifar100)\n",
    "\n",
    "\n",
    "resnet18_cifar100_da_cutout = resnet18_cifar100_da_cutout.cuda()\n",
    "learning_rate_cifar100_da_cutout = 0.1\n",
    "criterion_cifar100_da_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_cifar100_da_cutout = torch.optim.SGD(resnet18_cifar100_da_cutout.parameters(), lr=learning_rate_cifar100_da_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_cifar100_da_cutout = MultiStepLR(cnn_optimizer_cifar100_da_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "9c4b50fd-263d-42f5-aba1-f5aa0aa51720"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ResNet-18 with Cutout"
   ],
   "id": "33616d5d-88dd-4d20-885e-9c3f975c5e91"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "80271104-5a46-41ed-a075-1544c76c7662"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_da_co)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        resnet18_cifar100_da_cutout.zero_grad()\n",
    "        pred = resnet18_cifar100_da_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_cifar100_da_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_cifar100_da_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar100_da_cutout = test(test_loader_cifar100,resnet18_cifar100_da_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar100_da_cutout))\n",
    "    scheduler_cifar100_da_cutout.step()     \n",
    "torch.save(resnet18_cifar100_da_cutout.state_dict(),current_path +  'checkpoints/' + file_name_resnet18_cifar100_da_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_resnet18_cifar100_da_cutout = (1 - test(test_loader_cifar100,resnet18_cifar100_da_cutout))*100\n",
    "print('Final Result ResNet-18 using Data Augmentation and  Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_da_cutout))"
   ],
   "id": "3465f946-0112-4d11-8989-20b76054211f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Result ResNet-18 without Cutout for Test CIFAR-100 Dataset: %.3f' % (final_test_acc_resnet18_cifar100))\n",
    "print('Final Result ResNet-18 using Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_cutout))\n",
    "print('Final Result ResNet-18 using Data Augmentation for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_da))\n",
    "print('Final Result ResNet-18 using Data Augmentation and  Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_resnet18_cifar100_da_cutout))"
   ],
   "id": "d74015df-16ec-417f-845f-60845606b466"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. WideResNet"
   ],
   "id": "38d018be-5cb3-4c03-b543-8298c61648d9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WideResNet model implementation from https://github.com/xternalz/WideResNet-pytorch\n",
    "\n",
    "Note: for faster training, use Runtime \\> Change Runtime Type to run this notebook on a GPU."
   ],
   "id": "a15458b7-6c61-466d-93e9-38c3ed1bfac9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": ::: {.cell .markdown}\n",
    "\n",
    "In the Cutout paper, the authors claim that:\n",
    "\n",
    "1.  Cutout improves the robustness and overall performance of convolutional neural networks.\n",
    "2.  Cutout can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance.\n",
    "\n",
    "In this section, we will evaluate these claims using a WideResNet model. For the WideResNet model, the specific quantitative claims are given in the following table:\n",
    "\n",
    "Test error (%, flip/translation augmentation, mean/std normalization, mean of 5 runs) and “+” indicates standard data augmentation (mirror + crop)\n",
    "\n",
    "| **Network**         | **CIFAR-10** | **CIFAR-10+** | **CIFAR-100** | **CIFAR-100+** | **SVHN** |\n",
    "|-----------|------------|-------------|------------|-------------|------------|\n",
    "| WideResNet          | 6.97         | 3.87          | 26.06         | 18.8           | 1.60     |\n",
    "| WideResNet + cutout | 5.54         | 3.08          | 23.94         | 18.41          | 1.30     |\n",
    "\n",
    "In this table, the effectiveness of standard and cutout data augmentation techniques is evaluated using the WideResNet architecture on the CIFAR-10, CIFAR-100, and SVHN datasets. The “+”, as before, indicates the use of standard data augmentation (mirror and crop).\n",
    "\n",
    "For CIFAR-10, utilizing the WideResNet model with standard augmentation significantly reduces the test error from 6.97% to 3.87%. When cutout augmentation is added, the error drops even further to 3.08%.\n",
    "\n",
    "A comparable trend is seen with the CIFAR-100 dataset. Standard augmentation reduces the WideResNet model’s test error from 26.06% to 18.8%. With the application of cutout augmentation, the error rate decreases slightly more to 18.41%.\n",
    "\n",
    "Lastly, the SVHN dataset shows the smallest error rates. With standard augmentation, the error is 1.60% which further reduces to 1.30% with the addition of cutout augmentation.\n",
    "\n",
    "These results demonstrate the robust effectiveness of both standard and cutout augmentation techniques in lowering test error rates across all tested datasets when used with the WideResNet model. As with the previous findings, the effect of augmentation appears to be influenced by the complexity of the dataset.\n",
    "\n",
    ":::"
   ],
   "id": "4e7be06d-0dac-44a2-9170-a385207e6b09"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ],
   "id": "35dcd91d-4fb9-4a05-ab8e-38b13aa31b6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math"
   ],
   "id": "5758867d-f61e-4dcf-a4fc-189b405b9cf8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Cuda GPU availability and set seed number"
   ],
   "id": "cc7ff182-893d-40dc-b665-7a3acdd14e35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "cudnn.benchmark = True  # Should make training should go faster for large models\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "id": "b67f89a5-e6cb-49b0-a874-5c9b82f4eb3f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, here’s a step-by-step how to connect with your google drive:\n",
    "\n",
    "1.  On the left sidebar of the Colab notebook interface, you will see a folder icon with the Google Drive logo. Click on this folder icon to open the file explorer.\n",
    "\n",
    "2.  If you haven’t connected your Google Drive to Colab yet, it will prompt you to do so. Click the “Mount Drive” button to connect your Google Drive to Colab.\n",
    "\n",
    "3.  Once your Google Drive is mounted, you can use the file explorer to navigate to the file you want to open. Click on the folders to explore the contents of your Google Drive.\n",
    "\n",
    "4.  When you find the file you want to open, click the three dots next to the name of the file in the file explorer. From the options that appear, choose “Copy path.” This action will copy the full path of the file to your clipboard. Paste the copy path into the ‘current_path’ below."
   ],
   "id": "f941dd4a-12e0-4e5b-b0d5-00ca5437531b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path =\"./\""
   ],
   "id": "55c07ed7-081b-4c1c-9166-ee7a94a668f4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is used for creating a directory named ‘checkpoints’. This directory will be used to store the weights of our models, which are crucial for both preserving our progress during model training and for future use of the trained models.\n",
    "\n",
    "Creating such a directory and regularly saving model weights is a good practice in machine learning, as it ensures that you can resume your work from where you left off, should the training process be interrupted."
   ],
   "id": "88d9b060-d173-4853-921f-0bc6bcedfecc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file names 'checkpoints' to save the weight of the models\n",
    "if not os.path.exists(current_path + 'checkpoints'):\n",
    "    os.makedirs(current_path + 'checkpoints')"
   ],
   "id": "8ef7a800-a1cd-4b6c-b472-98680659f4a6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implementation Code"
   ],
   "id": "4f25169f-3c11-4a8d-8f3c-766d94b06ef2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 WideResNet Code"
   ],
   "id": "49602a4f-2269-4c8e-9bcf-bfab13910e31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideResNet\n",
    "\n",
    "# From https://github.com/uoguelph-mlrg/Cutout/blob/master/model/wide_resnet.py\n",
    "\n",
    "\n",
    "class BasicBlockWide(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlockWide, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) // 6\n",
    "        block = BasicBlockWide\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "5aa301ac-369b-4378-ba7d-8b0deae21db7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Model Evaluate Test Code\n",
    "\n",
    "This function evaluates the performance of the model on a given data loader (loader). It sets the model to evaluation mode (eval), calculates the accuracy on the dataset, and returns the validation accuracy. It then switches the model back to training mode (train) before returning the validation accuracy."
   ],
   "id": "f6e8f46e-382a-4c2f-bdff-058214646137"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, cnn):\n",
    "    cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    for images, labels in loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = cnn(images)\n",
    "\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    cnn.train()\n",
    "    return val_acc"
   ],
   "id": "1aa0290f-2ef1-4dee-b8d0-9b2664ad3eb3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training WideResNet in CIFAR-10"
   ],
   "id": "617eabdb-3cb0-4971-92cd-76019c413139"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Training WideResNet in CF10 without Cutout"
   ],
   "id": "cace2387-8d76-4bb8-839b-04a3363126ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "3946c43b-d997-4d08-9eed-ca37c6c765fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10 = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar10.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "b1ed0771-06dc-4108-b4b6-e3c894ab7eeb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "48d16133-15ca-4b67-adf0-3adc51b46508"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "2965f4a2-971a-46e0-b705-2bb2952769be"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "c0b38a1a-e703-4310-936e-7a8e9f9aa6ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10 = 128\n",
    "train_loader_cifar10 = torch.utils.data.DataLoader(dataset=train_dataset_cifar10,\n",
    "                                           batch_size=batch_size_cifar10,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "c8cf3c65-9274-42c7-9b02-eb5580addcff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "7fc341a2-c9ad-4402-b822-ebb28ba27495"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "5d2ca780-b3a0-4cce-bdff-92fc7d0b3a8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar10 = \"wideresnet_cifar10\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "wideresnet_cifar10 = WideResNet(depth=28, num_classes=num_classes_cifar10, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar10 = wideresnet_cifar10.cuda()\n",
    "learning_rate_wideresnet_cifar10 = 0.1\n",
    "criterion_wideresnet_cifar10 = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar10 = torch.optim.SGD(wideresnet_cifar10.parameters(), lr=learning_rate_wideresnet_cifar10,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar10 = MultiStepLR(cnn_optimizer_wideresnet_cifar10, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "33d4fe1d-7747-4bec-bc06-be8aaeaac092"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet withuout Cutout"
   ],
   "id": "a9496771-73b0-4e74-848f-c21c2361b734"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "ba703d63-e61f-4cdb-9848-d7be018a60a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar10.zero_grad()\n",
    "        pred = wideresnet_cifar10(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar10(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar10.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_accr_wideresnet_cifar10 = test(test_loader_cifar10, wideresnet_cifar10)\n",
    "    tqdm.write('test_acc: %.3f' % (test_accr_wideresnet_cifar10))\n",
    "\n",
    "    scheduler_wideresnet_cifar10.step()    \n",
    "\n",
    "    \n",
    "torch.save(wideresnet_cifar10.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar10 + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar10 = (1 - test(test_loader_cifar10, wideresnet_cifar10))*100\n",
    "print('Final Result WideResNet without Cutout for Test CIFAR-10 Dataset: %.3f' % (final_test_acc_wideresnet_cifar10))"
   ],
   "id": "e909ce96-0886-4442-9289-253825cfb99d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Training WideResNet in CF10 with Cutout"
   ],
   "id": "84c6f29b-13d2-4bcb-8943-e407aa55893f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutout Code"
   ],
   "id": "d8f18ba9-a80f-4c6c-816f-d426ea97ef29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: link to the file in the original repo that this comes from\n",
    "# Source Code from https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ],
   "id": "18b7af33-0d9b-4e62-9bb4-5dbe9d1b1229"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "9c57e8df-3abd-477b-acb8-412ea6be6f7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_cutout = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar10_cutout.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_cutout.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar10 = 1\n",
    "length_cifar10 = 16\n",
    "train_transform_cifar10_cutout.transforms.append(Cutout(n_holes=n_holes_cifar10, length=length_cifar10))\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "6d18dc91-02be-4aef-a9cd-317ad822b72c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "0243eab3-0d28-4e0d-9717-dce686992d86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_cutout = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_cutout,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "c7081250-c434-4e00-ac78-9968c8f6a5ca"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "60b7ce86-c2fb-4257-ad1f-36108f337aae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_cutout = 128\n",
    "train_loader_cifar10_cutout = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_cutout,\n",
    "                                           batch_size=batch_size_cifar10_cutout,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_cutout,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "5c5b6676-41f3-47ed-b344-138fb5ed0fe9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "42bf5762-557e-42e3-bfde-2478e2212209"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "f7ddcc47-602f-488e-b57e-106e66a58e8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar10_cutout = \"wideresnet_cifar10_cutout\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "wideresnet_cifar10_cutout = WideResNet(depth=28, num_classes=num_classes_cifar10, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar10_cutout = wideresnet_cifar10_cutout.cuda()\n",
    "learning_rate_wideresnet_cifar10_cutout = 0.1\n",
    "criterion_wideresnet_cifar10_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar10_cutout = torch.optim.SGD(wideresnet_cifar10_cutout.parameters(), lr=learning_rate_wideresnet_cifar10_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar10_cutout = MultiStepLR(cnn_optimizer_wideresnet_cifar10_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "4a382771-526d-41a3-8849-42b521124c50"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Cutout"
   ],
   "id": "cca8926c-5b1c-429d-87e3-4c76838b128a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "025a50ed-dcc8-4ba3-a2ca-f809712e8451"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_cutout)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar10_cutout.zero_grad()\n",
    "        pred = wideresnet_cifar10_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar10_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar10_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar10 = test(test_loader_cifar10,wideresnet_cifar10_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar10))\n",
    "    scheduler_wideresnet_cifar10_cutout.step()     \n",
    "torch.save(wideresnet_cifar10_cutout.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar10_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar10_cutout = (1 - test(test_loader_cifar10,wideresnet_cifar10_cutout))*100\n",
    "print('Final Result WideResNet using Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_cutout))"
   ],
   "id": "a4dc63db-bca2-4520-a5d6-57175759b077"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Training WideResNet in CF10 with Data Augmentation"
   ],
   "id": "0ca708bf-45aa-4284-970f-e18d1930d5cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "5b2c24f0-e775-4e6a-ae0a-5c153043f91e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_da = transforms.Compose([])\n",
    "train_transform_cifar10_da.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar10_da.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar10_da.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_da.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "9c1a2940-2365-4f84-ae0f-5ae0aef1bc1c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "2712d088-6127-483c-a9b9-71b0c978a0a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_da = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_da,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "6f2d177a-4ed0-4b4a-8c17-44c0e745f871"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "838890d0-0e52-4b9b-8081-3e350e303e91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_da = 128\n",
    "train_loader_cifar10_da = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_da,\n",
    "                                           batch_size=batch_size_cifar10_da,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_da,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "5d3549c7-b6c5-48b6-8058-04ff39780a08"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "e9093c25-0731-42be-ad6e-53566192b04e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "5d9d0886-495d-4e2f-af57-0998a8a0b464"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar10_da = \"wideresnet_cifar10_da\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "wideresnet_cifar10_da = WideResNet(depth=28, num_classes=num_classes_cifar10, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar10_da = wideresnet_cifar10_da.cuda()\n",
    "learning_rate_wideresnet_cifar10_da = 0.1\n",
    "criterion_wideresnet_cifar10_da = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar10_da = torch.optim.SGD(wideresnet_cifar10_da.parameters(), lr=learning_rate_wideresnet_cifar10_da,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar10_da = MultiStepLR(cnn_optimizer_wideresnet_cifar10_da, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "ca016648-64de-4bb3-ba1d-d447ce881835"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Data Augmentation"
   ],
   "id": "fda47943-a30a-43a3-9cdb-bf335a0f981b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "87233758-273a-41a2-8538-58ed9bd78e04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_da)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar10_da.zero_grad()\n",
    "        pred = wideresnet_cifar10_da(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar10_da(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar10_da.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_wideresnet_cifar10_da = test(test_loader_cifar10,wideresnet_cifar10_da)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_wideresnet_cifar10_da))\n",
    "    scheduler_wideresnet_cifar10_da.step()     \n",
    "torch.save(wideresnet_cifar10_da.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar10_da + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar10_da = (1 - test(test_loader_cifar10,wideresnet_cifar10_da))*100\n",
    "print('Final Result WideResNet using Data Augmentation for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_da))"
   ],
   "id": "97a0c60b-8d93-462f-af0d-edbe8143d6bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Training WideResNet in CF10 with Data Augmentation with Cutout"
   ],
   "id": "0a76a190-7dbe-4244-960f-aab01d4f4802"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-10"
   ],
   "id": "3d58556a-91a3-46a3-a7c0-9f489f52ad3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar10 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar10_da_co = transforms.Compose([])\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar10_da_co.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar10_da_co.transforms.append(normalize_image_cifar10)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar10_da_co = 1\n",
    "length_cifar10_da_co = 16\n",
    "train_transform_cifar10_da_co.transforms.append(Cutout(n_holes=n_holes_cifar10_da_co, length=length_cifar10_da_co))\n",
    "\n",
    "\n",
    "test_transform_cifar10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar10])"
   ],
   "id": "49d5c1af-7b24-44bc-93dd-90cca975dbb7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-10"
   ],
   "id": "673d213e-1a6d-45fa-a4ef-0c86d0f73d80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar10_da_co = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar10_da_co,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar10 = datasets.CIFAR10(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar10,\n",
    "                                    download=True)"
   ],
   "id": "ea7cdb08-fc2e-4aa2-8a2f-51751589d6e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "10809068-eb1f-421b-8b2c-f5342d3957f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar10_da_co = 128\n",
    "train_loader_cifar10_da_co = torch.utils.data.DataLoader(dataset=train_dataset_cifar10_da_co,\n",
    "                                           batch_size=batch_size_cifar10_da_co,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(dataset=test_dataset_cifar10,\n",
    "                                          batch_size=batch_size_cifar10_da_co,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "e8e522fd-d731-4e81-93e3-97b98cae2bac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "4bae0c1e-4ab8-4c15-a5aa-c48dbe56bd2f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "4c0d8b2e-1a88-4467-aa3e-ac4d5b128d7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar10_da_cutout = \"wideresnet_cifar10_da_cutout\"\n",
    "\n",
    "num_classes_cifar10 = 10\n",
    "wideresnet_cifar10_da_cutout = WideResNet(depth=28, num_classes=num_classes_cifar10, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar10_da_cutout = wideresnet_cifar10_da_cutout.cuda()\n",
    "learning_rate_cifar10_da_cutout = 0.1\n",
    "criterion_cifar10_da_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_cifar10_da_cutout = torch.optim.SGD(wideresnet_cifar10_da_cutout.parameters(), lr=learning_rate_cifar10_da_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_cifar10_da_cutout = MultiStepLR(cnn_optimizer_cifar10_da_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "a12a4e16-bf9c-4649-a371-84710d77468f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Cutout"
   ],
   "id": "a67c99a0-252c-44df-a8a2-d97dd65b3816"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "355567df-8565-42e7-bd30-bdabfeac8a67"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar10_da_co)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar10_da_cutout.zero_grad()\n",
    "        pred = wideresnet_cifar10_da_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_cifar10_da_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_cifar10_da_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar10_da_cutout = test(test_loader_cifar10,wideresnet_cifar10_da_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar10_da_cutout))\n",
    "    scheduler_cifar10_da_cutout.step()     \n",
    "torch.save(wideresnet_cifar10_da_cutout.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar10_da_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar10_da_cutout = (1 - test(test_loader_cifar10,wideresnet_cifar10_da_cutout))*100\n",
    "print('Final Result WideResNet using Data Augmentation and  Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_da_cutout))"
   ],
   "id": "5966484f-6854-4b1f-ae92-278b79b2ed93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Result WideResNet without Cutout for Test CIFAR-10 Dataset: %.3f' % (final_test_acc_wideresnet_cifar10))\n",
    "print('Final Result WideResNet using Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_cutout))\n",
    "print('Final Result WideResNet using Data Augmentation for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_da))\n",
    "print('Final Result WideResNet using Data Augmentation and  Cutout for CIFAR-10 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar10_da_cutout))"
   ],
   "id": "52f2343b-9a51-43c8-9e34-4a37285e764b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Training WideResNet in CIFAR-100"
   ],
   "id": "54a3ed42-ac4d-4ffc-babe-066ccc41957b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Training WideResNet in CF100 without Cutout"
   ],
   "id": "b7f672f6-491f-4120-bd43-6b619bede4cb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "6ae362e0-ec6c-4745-a5f5-bfc15d421927"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100 = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar100.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "2426772c-7b2c-4fea-9aaf-15f867352e11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "76bfb4e5-705d-4cb5-b0d9-e57e1e350eb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100 = datasets.CIFAR100(root=current_path +  'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "6403b678-3091-4840-90a1-296c6d3bdb1e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "bf519272-fde2-4994-a4eb-690287a94b84"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100 = 128\n",
    "train_loader_cifar100 = torch.utils.data.DataLoader(dataset=train_dataset_cifar100,\n",
    "                                           batch_size=batch_size_cifar100,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "279e62f5-eef3-41ef-abd6-fefaa202a957"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "a5b87b86-1d09-4753-ab42-d16c0de205d2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "18c39275-9fb3-472d-804d-83ffc0087d79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar100 = \"wideresnet_cifar100\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "wideresnet_cifar100 = WideResNet(depth=28, num_classes=num_classes_cifar100, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar100 = wideresnet_cifar100.cuda()\n",
    "learning_rate_wideresnet_cifar100 = 0.1\n",
    "criterion_wideresnet_cifar100 = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar100 = torch.optim.SGD(wideresnet_cifar100.parameters(), lr=learning_rate_wideresnet_cifar100,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar100 = MultiStepLR(cnn_optimizer_wideresnet_cifar100, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "2ea93fce-c75b-4138-a78a-ba279d91bca6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet withuout Cutout"
   ],
   "id": "a669a046-672f-4f88-a81f-03449dc0eeed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "d0bfb7fd-46ce-430a-8ad2-ddd7f1d12f0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar100.zero_grad()\n",
    "        pred = wideresnet_cifar100(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar100(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar100.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_accr_wideresnet_cifar100 = test(test_loader_cifar100, wideresnet_cifar100)\n",
    "    tqdm.write('test_acc: %.3f' % (test_accr_wideresnet_cifar100))\n",
    "\n",
    "    scheduler_wideresnet_cifar100.step()    \n",
    "\n",
    "    \n",
    "torch.save(wideresnet_cifar100.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar100 + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar100 = (1 - test(test_loader_cifar100, wideresnet_cifar100))*100\n",
    "print('Final Result WideResNet without Cutout for Test CIFAR-100 Dataset: %.3f' % (final_test_acc_wideresnet_cifar100))"
   ],
   "id": "d0c3b0c4-6f7c-48a6-9df3-05603ccc5c78"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Training WideResNet in CF100 with Cutout"
   ],
   "id": "d4f271cb-0eba-4e34-a565-2f0534729d19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "2e37593b-caa2-44d6-9dbc-45ceb61f5383"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_cutout = transforms.Compose([])\n",
    "\n",
    "train_transform_cifar100_cutout.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_cutout.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar100 = 1\n",
    "length_cifar100 = 8\n",
    "train_transform_cifar100_cutout.transforms.append(Cutout(n_holes=n_holes_cifar100, length=length_cifar100))\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "1205276b-cf67-42d4-b6ea-bf82b72eee16"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-0"
   ],
   "id": "6f4a5f72-de78-4429-91a1-82f890764b99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_cutout = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_cutout,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "08246b2e-9cff-4fdf-8374-02f042f02741"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "76afdebc-7aa1-40b8-a5de-adc218526948"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_cutout = 128\n",
    "train_loader_cifar100_cutout = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_cutout,\n",
    "                                           batch_size=batch_size_cifar100_cutout,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_cutout,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "5ad6cc62-4705-464a-9a97-fa84c88be33e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "3be22243-859b-4c5f-8ade-99bb54354b79"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "1548d24a-1a00-4706-9576-5f352f1ddce8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar100_cutout = \"wideresnet_cifar100_cutout\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "wideresnet_cifar100_cutout = WideResNet(depth=28, num_classes=num_classes_cifar100, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar100_cutout = wideresnet_cifar100_cutout.cuda()\n",
    "learning_rate_wideresnet_cifar100_cutout = 0.1\n",
    "criterion_wideresnet_cifar100_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar100_cutout = torch.optim.SGD(wideresnet_cifar100_cutout.parameters(), lr=learning_rate_wideresnet_cifar100_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar100_cutout = MultiStepLR(cnn_optimizer_wideresnet_cifar100_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "67e1bc2b-943d-4e06-ac77-35ac91d3fa56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Cutout"
   ],
   "id": "64a0da78-a173-489f-b05d-87291a6142d8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "13220280-74a7-4c25-abb7-95d4561c456e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_cutout)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar100_cutout.zero_grad()\n",
    "        pred = wideresnet_cifar100_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar100_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar100_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar100 = test(test_loader_cifar100,wideresnet_cifar100_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar100))\n",
    "    scheduler_wideresnet_cifar100_cutout.step()     \n",
    "torch.save(wideresnet_cifar100_cutout.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar100_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar100_cutout = (1 - test(test_loader_cifar100,wideresnet_cifar100_cutout))*100\n",
    "print('Final Result WideResNet using Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_cutout))"
   ],
   "id": "540047a0-9b37-4c9f-95bd-be8af89f105f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Training WideResNet in CF100 with Data Augmentation"
   ],
   "id": "337ad3f7-9e95-4076-9ed2-de021258bffb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "b4a27521-6f5c-4e2d-93b4-81b550911bb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_da = transforms.Compose([])\n",
    "train_transform_cifar100_da.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar100_da.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar100_da.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_da.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "2c70cbfd-0ae2-451a-b189-bd958370adb3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "6067ce0a-7987-48d8-897a-8f118335bab0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_da = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_da,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "57dc67c0-44e5-4e5e-af96-0344c6c2a48a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "8fa88387-692a-458d-9812-2b908fd4906b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_da = 128\n",
    "train_loader_cifar100_da = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_da,\n",
    "                                           batch_size=batch_size_cifar100_da,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_da,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "f7d0ddc8-479e-4e48-9179-484e6053d911"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "9ed87698-cc06-4ba1-bd84-e5d9c6c5b768"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "52c822c1-3373-46f5-a544-467d64be4e66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar100_da = \"wideresnet_cifar100_da\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "wideresnet_cifar100_da = WideResNet(depth=28, num_classes=num_classes_cifar100, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "\n",
    "wideresnet_cifar100_da = wideresnet_cifar100_da.cuda()\n",
    "learning_rate_wideresnet_cifar100_da = 0.1\n",
    "criterion_wideresnet_cifar100_da = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_cifar100_da = torch.optim.SGD(wideresnet_cifar100_da.parameters(), lr=learning_rate_wideresnet_cifar100_da,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_cifar100_da = MultiStepLR(cnn_optimizer_wideresnet_cifar100_da, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "643a95e7-d80e-4cd8-bfcf-94c96fdc386c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Data Augmentation"
   ],
   "id": "eb506021-246d-476d-864a-b615c8c24442"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "58a3763a-f4da-4a78-bd19-c6f5420f2c48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_da)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar100_da.zero_grad()\n",
    "        pred = wideresnet_cifar100_da(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_cifar100_da(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_cifar100_da.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_wideresnet_cifar100_da = test(test_loader_cifar100,wideresnet_cifar100_da)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_wideresnet_cifar100_da))\n",
    "    scheduler_wideresnet_cifar100_da.step()     \n",
    "torch.save(wideresnet_cifar100_da.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar100_da + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar100_da = (1 - test(test_loader_cifar100,wideresnet_cifar100_da))*100\n",
    "print('Final Result WideResNet using Data Augmentation for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_da))"
   ],
   "id": "edd14b77-e589-445a-a34a-5d2bc4017d39"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Training WideResNet in CF100 with Data Augmentation with Cutout"
   ],
   "id": "27fd58ef-eece-49bf-8523-78969777289b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for CIFAR-100"
   ],
   "id": "e1e01d6e-eff5-488c-80e5-004bf6cd145e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_cifar100 = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "train_transform_cifar100_da_co = transforms.Compose([])\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.RandomHorizontalFlip())\n",
    "train_transform_cifar100_da_co.transforms.append(transforms.ToTensor())\n",
    "train_transform_cifar100_da_co.transforms.append(normalize_image_cifar100)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_cifar100_da_co = 1\n",
    "length_cifar100_da_co = 8\n",
    "train_transform_cifar100_da_co.transforms.append(Cutout(n_holes=n_holes_cifar100_da_co, length=length_cifar100_da_co))\n",
    "\n",
    "\n",
    "test_transform_cifar100 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_cifar100])"
   ],
   "id": "3a25d87f-2c5c-4c0e-b60b-aa42fbf3481e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of CIFAR-100"
   ],
   "id": "f435b854-00b0-450e-84bc-6359f9a05cca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_cifar100_da_co = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform_cifar100_da_co,\n",
    "                                     download=True)\n",
    "\n",
    "test_dataset_cifar100 = datasets.CIFAR100(root=current_path + 'data/',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform_cifar100,\n",
    "                                    download=True)"
   ],
   "id": "df21b2e5-6b00-4100-9e4a-1b6db5c32aa9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "f2513e97-3088-46e1-a379-a89333ee10b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_cifar100_da_co = 128\n",
    "train_loader_cifar100_da_co = torch.utils.data.DataLoader(dataset=train_dataset_cifar100_da_co,\n",
    "                                           batch_size=batch_size_cifar100_da_co,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_cifar100 = torch.utils.data.DataLoader(dataset=test_dataset_cifar100,\n",
    "                                          batch_size=batch_size_cifar100_da_co,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "82721aa0-25b4-4087-ad87-a7fd52336129"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "734b8f80-af4c-4ad3-87d9-55ce0b7ab8e5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "78adadcd-474e-4c7a-9e9e-a9af02f836f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_cifar100_da_cutout = \"wideresnet_cifar100_da_cutout\"\n",
    "\n",
    "num_classes_cifar100 = 100\n",
    "wideresnet_cifar100_da_cutout = WideResNet(depth=28, num_classes=num_classes_cifar100, widen_factor=10, dropRate=0.3)\n",
    "\n",
    "\n",
    "wideresnet_cifar100_da_cutout = wideresnet_cifar100_da_cutout.cuda()\n",
    "learning_rate_cifar100_da_cutout = 0.1\n",
    "criterion_cifar100_da_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_cifar100_da_cutout = torch.optim.SGD(wideresnet_cifar100_da_cutout.parameters(), lr=learning_rate_cifar100_da_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_cifar100_da_cutout = MultiStepLR(cnn_optimizer_cifar100_da_cutout, milestones=[60, 120, 160], gamma=0.2)"
   ],
   "id": "f3753801-e514-4f03-9c62-6010d82a9999"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Cutout"
   ],
   "id": "66b6362d-49fe-4a90-8bd8-b7faba1dc281"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "da22035e-2f07-4739-b51d-984b4da74a5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_cifar100_da_co)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_cifar100_da_cutout.zero_grad()\n",
    "        pred = wideresnet_cifar100_da_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_cifar100_da_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_cifar100_da_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_cifar100_da_cutout = test(test_loader_cifar100,wideresnet_cifar100_da_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_cifar100_da_cutout))\n",
    "    scheduler_cifar100_da_cutout.step()     \n",
    "torch.save(wideresnet_cifar100_da_cutout.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_cifar100_da_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_cifar100_da_cutout = (1 - test(test_loader_cifar100,wideresnet_cifar100_da_cutout))*100\n",
    "print('Final Result WideResNet using Data Augmentation and  Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_da_cutout))"
   ],
   "id": "6d4e4793-33b5-49b6-83e0-557941be1a5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Result WideResNet without Cutout for Test CIFAR-100 Dataset: %.3f' % (final_test_acc_wideresnet_cifar100))\n",
    "print('Final Result WideResNet using Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_cutout))\n",
    "print('Final Result WideResNet using Data Augmentation for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_da))\n",
    "print('Final Result WideResNet using Data Augmentation and  Cutout for CIFAR-100 Test Dataset: %.3f' % (final_test_acc_wideresnet_cifar100_da_cutout))"
   ],
   "id": "9b48a88e-8016-4655-b67e-4d2674cc40f6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Training WideResNet in SVHN"
   ],
   "id": "828fbc35-7625-4cfe-b2a2-445a3c1d36ce"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Training WideResNet in SVHN without Cutout"
   ],
   "id": "ac0a4da9-d67b-47ba-a54a-7ed9e6e2812f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for SVHN"
   ],
   "id": "b623896e-0c2a-4c1b-8244-dabe96c69b9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_svhn = transforms.Normalize(mean=[x / 255.0 for x in[109.9, 109.7, 113.8]],std=[x / 255.0 for x in [50.1, 50.6, 50.8]])\n",
    "\n",
    "train_transform_svhn = transforms.Compose([])\n",
    "\n",
    "train_transform_svhn.transforms.append(transforms.ToTensor())\n",
    "train_transform_svhn.transforms.append(normalize_image_svhn)\n",
    "\n",
    "\n",
    "\n",
    "test_transform_svhn = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_svhn])"
   ],
   "id": "4758a447-1aca-495c-b859-1dfcec7550f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of SVHN"
   ],
   "id": "c297c373-789d-428e-ae38-0d9d4fbb138c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_svhn = datasets.SVHN(root=current_path + 'data/',\n",
    "                                    split='train',\n",
    "                                    transform=train_transform_svhn,\n",
    "                                    download=True)\n",
    "\n",
    "extra_dataset_svhn = datasets.SVHN(root=current_path + 'data/',\n",
    "                                    split='extra',\n",
    "                                    transform=train_transform_svhn,\n",
    "                                    download=True)\n",
    "\n",
    "# Combine both training splits (https://arxiv.org/pdf/1605.07146.pdf)\n",
    "data_svhn = np.concatenate([train_dataset_svhn.data, extra_dataset_svhn.data], axis=0)\n",
    "labels_svhn = np.concatenate([train_dataset_svhn.labels, extra_dataset_svhn.labels], axis=0)\n",
    "train_dataset_svhn.data = data_svhn\n",
    "train_dataset_svhn.labels = labels_svhn\n",
    "\n",
    "test_dataset_svhn = datasets.SVHN(root=current_path + 'data/',\n",
    "                                  split='test',\n",
    "                                  transform=test_transform_svhn,\n",
    "                                  download=True)"
   ],
   "id": "e0aed507-b964-4385-88e3-561c9e8ea65e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "926a4abd-da1e-4033-8953-d62718ccd60f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_svhn = 128\n",
    "train_loader_svhn = torch.utils.data.DataLoader(dataset=train_dataset_svhn,\n",
    "                                           batch_size=batch_size_svhn,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_svhn = torch.utils.data.DataLoader(dataset=test_dataset_svhn,\n",
    "                                          batch_size=batch_size_svhn,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "a893ef0e-b5de-454d-8605-334684736e02"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "f19a8f2f-c9b7-4054-8be1-bfe4fa2e48e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "b227c91b-601d-486f-80a1-69bd15bfac39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_svhn = \"wideresnet_svhn\"\n",
    "\n",
    "num_classes_svhn = 10\n",
    "wideresnet_svhn = WideResNet(depth=16, num_classes=num_classes_svhn, widen_factor=8,dropRate=0.4)\n",
    "\n",
    "\n",
    "wideresnet_svhn = wideresnet_svhn.cuda()\n",
    "learning_rate_wideresnet_svhn = 0.01\n",
    "criterion_wideresnet_svhn = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_svhn = torch.optim.SGD(wideresnet_svhn.parameters(), lr=learning_rate_wideresnet_svhn,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_svhn = MultiStepLR(cnn_optimizer_wideresnet_svhn, milestones=[80, 120], gamma=0.1)"
   ],
   "id": "35161c6b-0244-434a-89bf-4741d00db8b8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet withuout Cutout"
   ],
   "id": "ecc1a441-1496-4d69-b21e-2768a1053ba9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "e0fbe0c4-667f-4282-8981-c167d541118f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 160\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_svhn)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_svhn.zero_grad()\n",
    "        pred = wideresnet_svhn(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_svhn(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_svhn.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_accr_wideresnet_svhn = test(test_loader_svhn, wideresnet_svhn)\n",
    "    tqdm.write('test_acc: %.3f' % (test_accr_wideresnet_svhn))\n",
    "\n",
    "    scheduler_wideresnet_svhn.step()     \n",
    "\n",
    "    \n",
    "torch.save(wideresnet_svhn.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_svhn + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_svhn = (1 - test(test_loader_svhn, wideresnet_svhn))*100\n",
    "print('Final Result WideResNet without Cutout for Test SVHN Dataset: %.3f' % (final_test_acc_wideresnet_svhn))"
   ],
   "id": "2a83cd0d-733e-48f1-905a-1f89e79b1c90"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Training WideResNet in SVHN with Cutout"
   ],
   "id": "783368e9-d519-475b-884a-00b29a3f8016"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing for SVHN"
   ],
   "id": "1ce43c99-de3a-47bb-849b-a39558b6b1b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "normalize_image_svhn = transforms.Normalize(mean=[x / 255.0 for x in[109.9, 109.7, 113.8]], std=[x / 255.0 for x in [50.1, 50.6, 50.8]])\n",
    "\n",
    "train_transform_svhn_cutout = transforms.Compose([])\n",
    "\n",
    "train_transform_svhn_cutout.transforms.append(transforms.ToTensor())\n",
    "train_transform_svhn_cutout.transforms.append(normalize_image_svhn)\n",
    "\n",
    "#Add Cutout to the image transformer pipeline\n",
    "n_holes_svhn = 1\n",
    "length_svhn = 20\n",
    "train_transform_svhn_cutout.transforms.append(Cutout(n_holes=n_holes_svhn, length=length_svhn))\n",
    "\n",
    "\n",
    "test_transform_svhn = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_image_svhn])"
   ],
   "id": "1bf67cd2-07be-4d6a-bfec-cefbdf21077c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset of SVHN"
   ],
   "id": "9692b9e7-b9ad-4774-bf52-5871ddcb4bf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_svhn_cutout = datasets.SVHN(root=current_path + 'data/',\n",
    "                                    split='train',\n",
    "                                    transform=train_transform_svhn_cutout,\n",
    "                                    download=True)\n",
    "\n",
    "extra_dataset_svhn_cutout = datasets.SVHN(root=current_path + 'data/',\n",
    "                                    split='extra',\n",
    "                                    transform=train_transform_svhn_cutout,\n",
    "                                    download=True)\n",
    "\n",
    "# Combine both training splits (https://arxiv.org/pdf/1605.07146.pdf)\n",
    "data_svhn_cutout = np.concatenate([train_dataset_svhn_cutout.data, extra_dataset_svhn_cutout.data], axis=0)\n",
    "labels_svhn_cutout = np.concatenate([train_dataset_svhn_cutout.labels, extra_dataset_svhn_cutout.labels], axis=0)\n",
    "train_dataset_svhn_cutout.data = data_svhn_cutout\n",
    "train_dataset_svhn_cutout.labels = labels_svhn_cutout\n",
    "\n",
    "test_dataset_svhn = datasets.SVHN(root=current_path + 'data/',\n",
    "                                  split='test',\n",
    "                                  transform=test_transform_svhn,\n",
    "                                  download=True)"
   ],
   "id": "dbea85c5-2abd-43c6-a031-7655e819eee9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset as Dataloader"
   ],
   "id": "0229ca68-8934-44ed-9a5e-4b3fe9629d96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "batch_size_svhn_cutout = 128\n",
    "train_loader_svhn_cutout = torch.utils.data.DataLoader(dataset=train_dataset_svhn_cutout,\n",
    "                                           batch_size=batch_size_svhn_cutout,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader_svhn = torch.utils.data.DataLoader(dataset=test_dataset_svhn,\n",
    "                                          batch_size=batch_size_svhn_cutout,\n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True,\n",
    "                                          num_workers=2)"
   ],
   "id": "6c05e9cb-ac25-4be3-8063-acad15a6ccef"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ],
   "id": "8c37af45-b950-4555-88ea-494f3cf804e7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up the machine learning model, loss function, optimizer, and learning rate scheduler."
   ],
   "id": "513b4b74-e5e3-440b-8845-f19b6e381d7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name will be the used for the name of the file of weight of the model and also the result\n",
    "file_name_wideresnet_svhn_cutout = \"wideresnet_svhn_cutout\"\n",
    "\n",
    "num_classes_svhn = 10\n",
    "wideresnet_svhn_cutout = WideResNet(depth=16, num_classes=num_classes_svhn, widen_factor=8,dropRate=0.4)\n",
    "\n",
    "\n",
    "wideresnet_svhn_cutout = wideresnet_svhn_cutout.cuda()\n",
    "learning_rate_wideresnet_svhn_cutout = 0.01\n",
    "criterion_wideresnet_svhn_cutout = nn.CrossEntropyLoss().cuda()\n",
    "cnn_optimizer_wideresnet_svhn_cutout = torch.optim.SGD(wideresnet_svhn_cutout.parameters(), lr=learning_rate_wideresnet_svhn_cutout,\n",
    "                                momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "scheduler_wideresnet_svhn_cutout = MultiStepLR(cnn_optimizer_wideresnet_svhn_cutout, milestones=[80, 120], gamma=0.1)"
   ],
   "id": "510a5c88-38aa-4cf0-8271-3a1faadfb635"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training WideResNet with Cutout"
   ],
   "id": "031c05b4-313b-45a9-96cc-ef4508912a92"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the training loop for the chosen machine learning model over a specified number of epochs. Each epoch involves a forward pass, loss computation, backpropagation, and parameter updates. It also calculates and displays the training accuracy and cross-entropy loss. At the end of each epoch, the model’s performance is evaluated on the test set, and the results are logged and saved."
   ],
   "id": "f11ffb44-5234-4919-adbc-ba39fa459618"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 160\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    xentropy_loss_avg = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    progress_bar = tqdm(train_loader_svhn_cutout)\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        wideresnet_svhn_cutout.zero_grad()\n",
    "        pred = wideresnet_svhn_cutout(images)\n",
    "\n",
    "        xentropy_loss = criterion_wideresnet_svhn_cutout(pred, labels)\n",
    "        xentropy_loss.backward()\n",
    "        cnn_optimizer_wideresnet_svhn_cutout.step()\n",
    "\n",
    "        xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "        # Calculate running average of accuracy\n",
    "        pred = torch.max(pred.data, 1)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels.data).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "            acc='%.3f' % accuracy)\n",
    "\n",
    "    test_acc_svhn = test(test_loader_svhn,wideresnet_svhn_cutout)\n",
    "    tqdm.write('test_acc: %.3f' % (test_acc_svhn))\n",
    "    scheduler_wideresnet_svhn_cutout.step()     \n",
    "torch.save(wideresnet_svhn_cutout.state_dict(), current_path + 'checkpoints/' + file_name_wideresnet_svhn_cutout + '.pt')\n",
    "\n",
    "\n",
    "final_test_acc_wideresnet_svhn_cutout = (1 - test(test_loader_svhn,wideresnet_svhn_cutout))*100\n",
    "print('Final Result WideResNet using Cutout for SVHN Test Dataset: %.3f' % (final_test_acc_wideresnet_svhn_cutout))"
   ],
   "id": "228e9bfd-04cc-4ceb-b100-05828b7d8445"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Result WideResNet without Cutout for Test SVHN Dataset: %.3f' % (final_test_acc_wideresnet_svhn))\n",
    "print('Final Result WideResNet using Cutout for SVHN Test Dataset: %.3f' % (final_test_acc_wideresnet_svhn_cutout))"
   ],
   "id": "da806ede-5282-4620-8160-8b650ee5e400"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Grad-CAM"
   ],
   "id": "f8c938e5-4767-4dc4-9a8b-6350c22b44aa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is Grad-CAM?\n",
    "\n",
    "Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique that provides visual explanations for decisions made by Convolutional Neural Network (CNN) models. It uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.\n",
    "\n",
    "Grad-CAM is not limited to a specific architecture, it can be applied to a wide range of CNN models without any changes to their existing structure or requiring re-training. It’s also class-discriminative, allowing it to effectively manage multi-label scenarios.\n",
    "\n",
    "By visualizing the model’s focus areas with Grad-CAM, we can assess how effectively Cutout is encouraging the model to use a broader range of features. For example, if a model trained with Cutout still primarily focuses on a single region, that might suggest the Cutout squares are too small, or not numerous enough. Conversely, if the focus areas are well spread across the image, it would confirm that Cutout is indeed pushing the model to generalize better.\n",
    "\n",
    "If you want to understand more about Grad-CAM? Check this paper (https://arxiv.org/abs/1610.02391)"
   ],
   "id": "433dfcbd-bd7a-428b-9826-dc4a0d0ef81a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ],
   "id": "9b73d30f-3f94-434c-a38f-4f385ac9e39c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ],
   "id": "57945c50-d1da-43a7-aea1-22c0e622d597"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Cuda GPU availability and set seed number"
   ],
   "id": "231df155-8ce4-46db-9c18-72556fc5b1eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)\n",
    "cudnn.benchmark = True  # Should make training should go faster for large models\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ],
   "id": "f6839993-d242-4991-ae34-cfa0fb970e9c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, here’s a step-by-step how to connect with your google drive:\n",
    "\n",
    "1.  On the left sidebar of the Colab notebook interface, you will see a folder icon with the Google Drive logo. Click on this folder icon to open the file explorer.\n",
    "\n",
    "2.  If you haven’t connected your Google Drive to Colab yet, it will prompt you to do so. Click the “Mount Drive” button to connect your Google Drive to Colab.\n",
    "\n",
    "3.  Once your Google Drive is mounted, you can use the file explorer to navigate to the file you want to open. Click on the folders to explore the contents of your Google Drive.\n",
    "\n",
    "4.  When you find the file you want to open, click the three dots next to the name of the file in the file explorer. From the options that appear, choose “Copy path.” This action will copy the full path of the file to your clipboard. Paste the copy path into the ‘current_path’ below."
   ],
   "id": "3833b0dd-cfdf-48a4-91fb-76d89775c30e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path =\"./\""
   ],
   "id": "966cd6dd-e8e1-420b-b76e-a1a511be7535"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Implementation Grad-CAM for ResNet Model"
   ],
   "id": "26a44d34-d0fc-47b6-a93b-3013f06aed1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet\n",
    "# From https://github.com/uoguelph-mlrg/Cutout/blob/master/model/resnet.py\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = conv3x3(3,64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "        # Register hooks for Grad-CAM\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.layer4.register_forward_hook(self._store_activations_hook)\n",
    "        self.layer4.register_backward_hook(self._store_gradients_hook)\n",
    "\n",
    "    def _store_activations_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _store_gradients_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out) \n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)"
   ],
   "id": "fd0ef598-546b-475b-bc9b-09451de5c87c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Implementation Grad-CAM for ResNet18 Model for CIFAR-10"
   ],
   "id": "cf8920ee-a743-4340-a397-a0b669efac06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet18_gradcam_cifar10 = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar10.pt\"))\n",
    "resnet18_gradcam_cifar10.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_cutout = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_cutout.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar10_cutout.pt\"))\n",
    "resnet18_gradcam_cifar10_cutout.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_da = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_da.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar10_da.pt\"))\n",
    "resnet18_gradcam_cifar10_da.eval()\n",
    "\n",
    "resnet18_gradcam_cifar10_da_cutout = ResNet18(num_classes=10)\n",
    "resnet18_gradcam_cifar10_da_cutout.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar10_da_cutout.pt\"))\n",
    "resnet18_gradcam_cifar10_da_cutout.eval()"
   ],
   "id": "649473e1-2306-4a24-a5b2-a55d1ca1f3bf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to see the result from the testloader of CIFAR-10 dataset"
   ],
   "id": "d6bb9941-7534-40e4-a263-4500fd08ee34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cifar10 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=1, shuffle=True, num_workers=2)\n"
   ],
   "id": "88e0cd46-1d06-4290-b55e-624198b4f265"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = [\n",
    "    \"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n",
    "    \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"\n",
    "]"
   ],
   "id": "639476a1-8cce-4d93-ab39-df287c74234f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the testloader\n",
    "images, labels = next(iter(testloader_cifar10))\n",
    "input_tensor = images  # As your batch_size is 1, you will have a single image here\n",
    "\n",
    "# Forward pass\n",
    "resnet18_gradcam_cifar10.zero_grad()\n",
    "output_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_resnet18_gradcam_cifar10 = output_resnet18_gradcam_cifar10.argmax(1)\n",
    "output_resnet18_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_cutout = output_resnet18_gradcam_cifar10_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da = output_resnet18_gradcam_cifar10_da.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da_cutout = output_resnet18_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da = cifar10_classes[target_resnet18_gradcam_cifar10_da.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da_cutout = cifar10_classes[target_resnet18_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_resnet18_gradcam_cifar10 = gradients_resnet18_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_cutout = gradients_resnet18_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da = gradients_resnet18_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da_cutout = gradients_resnet18_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_resnet18_gradcam_cifar10 = (weights_resnet18_gradcam_cifar10 * activations_resnet18_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10 = F.relu(cam_resnet18_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10 = F.interpolate(cam_resnet18_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10 = cam_resnet18_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout = (weights_resnet18_gradcam_cifar10_cutout * activations_resnet18_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.relu(cam_resnet18_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_cutout = cam_resnet18_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da = (weights_resnet18_gradcam_cifar10_da * activations_resnet18_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da = F.relu(cam_resnet18_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da = F.interpolate(cam_resnet18_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da = cam_resnet18_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = (weights_resnet18_gradcam_cifar10_da_cutout * activations_resnet18_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.relu(cam_resnet18_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = cam_resnet18_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_resnet18_gradcam_cifar10 -= cam_resnet18_gradcam_cifar10.min()\n",
    "cam_resnet18_gradcam_cifar10 /= cam_resnet18_gradcam_cifar10.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout -= cam_resnet18_gradcam_cifar10_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_cutout /= cam_resnet18_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da -= cam_resnet18_gradcam_cifar10_da.min()\n",
    "cam_resnet18_gradcam_cifar10_da /= cam_resnet18_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout -= cam_resnet18_gradcam_cifar10_da_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_da_cutout /= cam_resnet18_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "img = images.squeeze().detach().cpu() * std[..., None, None] + mean[..., None, None]\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10 = heatmap_resnet18_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_cutout = heatmap_resnet18_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da = heatmap_resnet18_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da_cutout = heatmap_resnet18_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_resnet18_gradcam_cifar10 / 255)\n",
    "ax[1].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_resnet18_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_resnet18_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_resnet18_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_resnet18_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_resnet18_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "d0123530-042e-4518-8bec-446ce8b3fd85"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try to load your image, preprocess it and convert it into a PyTorch tensor. Choose an image that is in the CIFAR-10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks). The preprocessing steps should be the same as the ones you used for training your model. Let’s say you have an image `image.jpeg`:"
   ],
   "id": "577c55d9-3cdd-48af-aa87-a755cb6f0293"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = \"image.jpeg\"\n",
    "image = Image.open(current_path + image_path)\n",
    "\n",
    "# Define the transformations: resize, to tensor, normalize (replace the mean and std with values you used for training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # add batch dimension.  C,H,W => B,C,H,W"
   ],
   "id": "1c12dd5c-943b-46a4-9378-d1e370daa7b3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Grad-CAM"
   ],
   "id": "7d141945-204e-42b1-8fad-0cbb428e217e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "resnet18_gradcam_cifar10.zero_grad()\n",
    "output_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_resnet18_gradcam_cifar10 = output_resnet18_gradcam_cifar10.argmax(1)\n",
    "output_resnet18_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_cutout = output_resnet18_gradcam_cifar10_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da = output_resnet18_gradcam_cifar10_da.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar10_da_cutout = output_resnet18_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10 = cifar10_classes[target_resnet18_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da = cifar10_classes[target_resnet18_gradcam_cifar10_da.item()]\n",
    "predicted_class_resnet18_gradcam_cifar10_da_cutout = cifar10_classes[target_resnet18_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10 = resnet18_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_cutout = resnet18_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da = resnet18_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar10_da_cutout = resnet18_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_resnet18_gradcam_cifar10 = gradients_resnet18_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_cutout = gradients_resnet18_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da = gradients_resnet18_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar10_da_cutout = gradients_resnet18_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_resnet18_gradcam_cifar10 = (weights_resnet18_gradcam_cifar10 * activations_resnet18_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10 = F.relu(cam_resnet18_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10 = F.interpolate(cam_resnet18_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10 = cam_resnet18_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout = (weights_resnet18_gradcam_cifar10_cutout * activations_resnet18_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.relu(cam_resnet18_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_cutout = cam_resnet18_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da = (weights_resnet18_gradcam_cifar10_da * activations_resnet18_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da = F.relu(cam_resnet18_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da = F.interpolate(cam_resnet18_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da = cam_resnet18_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = (weights_resnet18_gradcam_cifar10_da_cutout * activations_resnet18_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.relu(cam_resnet18_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = F.interpolate(cam_resnet18_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar10_da_cutout = cam_resnet18_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_resnet18_gradcam_cifar10 -= cam_resnet18_gradcam_cifar10.min()\n",
    "cam_resnet18_gradcam_cifar10 /= cam_resnet18_gradcam_cifar10.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_cutout -= cam_resnet18_gradcam_cifar10_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_cutout /= cam_resnet18_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da -= cam_resnet18_gradcam_cifar10_da.min()\n",
    "cam_resnet18_gradcam_cifar10_da /= cam_resnet18_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar10_da_cutout -= cam_resnet18_gradcam_cifar10_da_cutout.min()\n",
    "cam_resnet18_gradcam_cifar10_da_cutout /= cam_resnet18_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "img = cv2.imread(current_path + image_path)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10 = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10 = heatmap_resnet18_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_cutout = heatmap_resnet18_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da = heatmap_resnet18_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar10_da_cutout = heatmap_resnet18_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())"
   ],
   "id": "aa7e7ea4-b5bd-4493-8c73-3b91544c0596"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the image and the Grad-CAM heatmap"
   ],
   "id": "f168d7ab-32ff-47c4-af72-773a836fb4f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_resnet18_gradcam_cifar10 / 255)\n",
    "ax[1].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_resnet18_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_resnet18_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_resnet18_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_resnet18_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_resnet18_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_resnet18_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "03bc5aba-a057-4787-9aa5-ace6ad19df99"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#START HERE"
   ],
   "id": "86d54e81-b0dd-41da-82ba-4ec542ef88ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2 Implementation Grad-CAM for ResNet18 Model for CIFAR-100"
   ],
   "id": "7f3ccac3-8f65-4fe7-9b68-8d3a1cf5de2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resnet18_gradcam_cifar100 = ResNet18(num_classes=100)\n",
    "resnet18_gradcam_cifar100.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar100.pt\"))\n",
    "resnet18_gradcam_cifar100.eval()\n",
    "\n",
    "resnet18_gradcam_cifar100_cutout = ResNet18(num_classes=100)\n",
    "resnet18_gradcam_cifar100_cutout.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar100_cutout.pt\"))\n",
    "resnet18_gradcam_cifar100_cutout.eval()\n",
    "\n",
    "resnet18_gradcam_cifar100_da = ResNet18(num_classes=100)\n",
    "resnet18_gradcam_cifar100_da.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar100_da.pt\"))\n",
    "resnet18_gradcam_cifar100_da.eval()\n",
    "\n",
    "resnet18_gradcam_cifar100_da_cutout = ResNet18(num_classes=100)\n",
    "resnet18_gradcam_cifar100_da_cutout.load_state_dict(torch.load(current_path + \"checkpoints/resnet18_cifar100_da_cutout.pt\"))\n",
    "resnet18_gradcam_cifar100_da_cutout.eval()"
   ],
   "id": "e4498e1f-23dd-4cc5-9dfc-a19deecfa473"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to see the result from the testloader of CIFAR-10 dataset"
   ],
   "id": "c16ab031-e009-49c8-894c-c236860bd7df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cifar100 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset_cifar100 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar100)\n",
    "testloader_cifar100 = torch.utils.data.DataLoader(testset_cifar100, batch_size=1, shuffle=True, num_workers=2)\n"
   ],
   "id": "1a22c3cd-4b15-4a3c-85fd-1c8f6236be82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_classes = [\n",
    "    \"Apple\", \"Aquarium fish\", \"Baby\", \"Bear\", \"Beaver\", \"Bed\", \"Bee\", \"Beetle\", \n",
    "    \"Bicycle\", \"Bottle\", \"Bowl\", \"Boy\", \"Bridge\", \"Bus\", \"Butterfly\", \"Camel\", \n",
    "    \"Can\", \"Castle\", \"Caterpillar\", \"Cattle\", \"Chair\", \"Chimpanzee\", \"Clock\", \n",
    "    \"Cloud\", \"Cockroach\", \"Couch\", \"Crab\", \"Crocodile\", \"Cup\", \"Dinosaur\", \n",
    "    \"Dolphin\", \"Elephant\", \"Flatfish\", \"Forest\", \"Fox\", \"Girl\", \"Hamster\", \n",
    "    \"House\", \"Kangaroo\", \"Computer keyboard\", \"Lamp\", \"Lawn-mower\", \"Leopard\", \"Lion\",\n",
    "    \"Lizard\", \"Lobster\", \"Man\", \"Maple tree\", \"Motorcycle\", \"Mountain\", \"Mouse\",\n",
    "    \"Mushrooms\", \"Oak tree\", \"Oranges\", \"Orchids\", \"Otter\", \"Palm tree\", \"Pears\",\n",
    "    \"Pickup truck\", \"Pine tree\", \"Plain\", \"Plates\", \"Poppies\", \"Porcupine\",\n",
    "    \"Possum\", \"Rabbit\", \"Raccoon\", \"Ray\", \"Road\", \"Rocket\", \"Roses\", \"Sea\", \"Seal\",\n",
    "    \"Shark\", \"Shrew\", \"Skunk\", \"Skyscraper\", \"Snail\", \"Snake\", \"Spider\", \"Squirrel\",\n",
    "    \"Streetcar\", \"Sunflowers\", \"Sweet peppers\", \"Table\", \"Tank\", \"Telephone\", \"Television\", \n",
    "    \"Tiger\", \"Tractor\", \"Train\", \"Trout\", \"Tulips\", \"Turtle\", \"Wardrobe\", \"Whale\", \n",
    "    \"Willow tree\", \"Wolf\", \"Woman\", \"Worm\"\n",
    "]\n"
   ],
   "id": "cbd48621-56bd-4ec6-a905-8b4490637090"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the testloader\n",
    "images, labels = next(iter(testloader_cifar100))\n",
    "input_tensor = images  # As your batch_size is 1, you will have a single image here\n",
    "\n",
    "# Forward pass\n",
    "resnet18_gradcam_cifar100.zero_grad()\n",
    "output_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_da.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_da_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_resnet18_gradcam_cifar100 = output_resnet18_gradcam_cifar100.argmax(1)\n",
    "output_resnet18_gradcam_cifar100.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_cutout = output_resnet18_gradcam_cifar100_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_cutout.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_da = output_resnet18_gradcam_cifar100_da.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_da.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_da_cutout = output_resnet18_gradcam_cifar100_da_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_resnet18_gradcam_cifar100 = cifar100_classes[target_resnet18_gradcam_cifar100.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100 = cifar100_classes[target_resnet18_gradcam_cifar100_cutout.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100_da = cifar100_classes[target_resnet18_gradcam_cifar100_da.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100_da_cutout = cifar100_classes[target_resnet18_gradcam_cifar100_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_resnet18_gradcam_cifar100 = gradients_resnet18_gradcam_cifar100.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_cutout = gradients_resnet18_gradcam_cifar100_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_da = gradients_resnet18_gradcam_cifar100_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_da_cutout = gradients_resnet18_gradcam_cifar100_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_resnet18_gradcam_cifar100 = (weights_resnet18_gradcam_cifar100 * activations_resnet18_gradcam_cifar100).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100 = F.relu(cam_resnet18_gradcam_cifar100)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100 = F.interpolate(cam_resnet18_gradcam_cifar100, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100 = cam_resnet18_gradcam_cifar100.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_cutout = (weights_resnet18_gradcam_cifar100_cutout * activations_resnet18_gradcam_cifar100_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_cutout = F.relu(cam_resnet18_gradcam_cifar100_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_cutout = F.interpolate(cam_resnet18_gradcam_cifar100_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_cutout = cam_resnet18_gradcam_cifar100_cutout.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da = (weights_resnet18_gradcam_cifar100_da * activations_resnet18_gradcam_cifar100_da).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_da = F.relu(cam_resnet18_gradcam_cifar100_da)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_da = F.interpolate(cam_resnet18_gradcam_cifar100_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_da = cam_resnet18_gradcam_cifar100_da.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = (weights_resnet18_gradcam_cifar100_da_cutout * activations_resnet18_gradcam_cifar100_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = F.relu(cam_resnet18_gradcam_cifar100_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = F.interpolate(cam_resnet18_gradcam_cifar100_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = cam_resnet18_gradcam_cifar100_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_resnet18_gradcam_cifar100 -= cam_resnet18_gradcam_cifar100.min()\n",
    "cam_resnet18_gradcam_cifar100 /= cam_resnet18_gradcam_cifar100.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_cutout -= cam_resnet18_gradcam_cifar100_cutout.min()\n",
    "cam_resnet18_gradcam_cifar100_cutout /= cam_resnet18_gradcam_cifar100_cutout.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da -= cam_resnet18_gradcam_cifar100_da.min()\n",
    "cam_resnet18_gradcam_cifar100_da /= cam_resnet18_gradcam_cifar100_da.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da_cutout -= cam_resnet18_gradcam_cifar100_da_cutout.min()\n",
    "cam_resnet18_gradcam_cifar100_da_cutout /= cam_resnet18_gradcam_cifar100_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "img = images.squeeze().detach().cpu() * std[..., None, None] + mean[..., None, None]\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_resnet18_gradcam_cifar100 = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100 = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100 = heatmap_resnet18_gradcam_cifar100 * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_cutout = heatmap_resnet18_gradcam_cifar100_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_da = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_da), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_da = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_da = heatmap_resnet18_gradcam_cifar100_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_da_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_da_cutout = heatmap_resnet18_gradcam_cifar100_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar100_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_resnet18_gradcam_cifar100 / 255)\n",
    "ax[1].set_title(predicted_class_resnet18_gradcam_cifar100)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_resnet18_gradcam_cifar100_cutout / 255)\n",
    "ax[2].set_title(predicted_class_resnet18_gradcam_cifar100)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_resnet18_gradcam_cifar100_da / 255)\n",
    "ax[3].set_title(predicted_class_resnet18_gradcam_cifar100_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_resnet18_gradcam_cifar100_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_resnet18_gradcam_cifar100_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "ac480c3a-06cb-45f1-8548-1db4ddcc9101"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try to load your image, preprocess it and convert it into a PyTorch tensor. Choose an image that is in the CIFAR-10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks). The preprocessing steps should be the same as the ones you used for training your model. Let’s say you have an image `image.jpeg`:"
   ],
   "id": "c7695113-1629-41e3-a1e7-f9eb63cd94d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = \"image.jpeg\"\n",
    "image = Image.open(current_path + image_path)\n",
    "\n",
    "# Define the transformations: resize, to tensor, normalize (replace the mean and std with values you used for training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # add batch dimension.  C,H,W => B,C,H,W"
   ],
   "id": "d2493835-c6b2-45bb-8b08-5d78e63f5791"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Grad-CAM"
   ],
   "id": "9d915e37-d063-49c5-acaf-cf0d258f3cbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "resnet18_gradcam_cifar100.zero_grad()\n",
    "output_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_da.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da(input_tensor)\n",
    "\n",
    "resnet18_gradcam_cifar100_da_cutout.zero_grad()\n",
    "output_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_resnet18_gradcam_cifar100 = output_resnet18_gradcam_cifar100.argmax(1)\n",
    "output_resnet18_gradcam_cifar100.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_cutout = output_resnet18_gradcam_cifar100_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_cutout.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_da = output_resnet18_gradcam_cifar100_da.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_da.max().backward()\n",
    "\n",
    "target_resnet18_gradcam_cifar100_da_cutout = output_resnet18_gradcam_cifar100_da_cutout.argmax(1)\n",
    "output_resnet18_gradcam_cifar100_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_resnet18_gradcam_cifar100 = cifar100_classes[target_resnet18_gradcam_cifar100.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100 = cifar100_classes[target_resnet18_gradcam_cifar100_cutout.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100_da = cifar100_classes[target_resnet18_gradcam_cifar100_da.item()]\n",
    "predicted_class_resnet18_gradcam_cifar100_da_cutout = cifar100_classes[target_resnet18_gradcam_cifar100_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100 = resnet18_gradcam_cifar100.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_cutout = resnet18_gradcam_cifar100_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_da = resnet18_gradcam_cifar100_da.activations.detach().cpu()\n",
    "\n",
    "gradients_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout.gradients.detach().cpu()\n",
    "activations_resnet18_gradcam_cifar100_da_cutout = resnet18_gradcam_cifar100_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_resnet18_gradcam_cifar100 = gradients_resnet18_gradcam_cifar100.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_cutout = gradients_resnet18_gradcam_cifar100_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_da = gradients_resnet18_gradcam_cifar100_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_resnet18_gradcam_cifar100_da_cutout = gradients_resnet18_gradcam_cifar100_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_resnet18_gradcam_cifar100 = (weights_resnet18_gradcam_cifar100 * activations_resnet18_gradcam_cifar100).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100 = F.relu(cam_resnet18_gradcam_cifar100)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100 = F.interpolate(cam_resnet18_gradcam_cifar100, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100 = cam_resnet18_gradcam_cifar100.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_cutout = (weights_resnet18_gradcam_cifar100_cutout * activations_resnet18_gradcam_cifar100_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_cutout = F.relu(cam_resnet18_gradcam_cifar100_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_cutout = F.interpolate(cam_resnet18_gradcam_cifar100_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_cutout = cam_resnet18_gradcam_cifar100_cutout.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da = (weights_resnet18_gradcam_cifar100_da * activations_resnet18_gradcam_cifar100_da).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_da = F.relu(cam_resnet18_gradcam_cifar100_da)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_da = F.interpolate(cam_resnet18_gradcam_cifar100_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_da = cam_resnet18_gradcam_cifar100_da.squeeze().numpy()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = (weights_resnet18_gradcam_cifar100_da_cutout * activations_resnet18_gradcam_cifar100_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = F.relu(cam_resnet18_gradcam_cifar100_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = F.interpolate(cam_resnet18_gradcam_cifar100_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_resnet18_gradcam_cifar100_da_cutout = cam_resnet18_gradcam_cifar100_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_resnet18_gradcam_cifar100 -= cam_resnet18_gradcam_cifar100.min()\n",
    "cam_resnet18_gradcam_cifar100 /= cam_resnet18_gradcam_cifar100.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_cutout -= cam_resnet18_gradcam_cifar100_cutout.min()\n",
    "cam_resnet18_gradcam_cifar100_cutout /= cam_resnet18_gradcam_cifar100_cutout.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da -= cam_resnet18_gradcam_cifar100_da.min()\n",
    "cam_resnet18_gradcam_cifar100_da /= cam_resnet18_gradcam_cifar100_da.max()\n",
    "\n",
    "cam_resnet18_gradcam_cifar100_da_cutout -= cam_resnet18_gradcam_cifar100_da_cutout.min()\n",
    "cam_resnet18_gradcam_cifar100_da_cutout /= cam_resnet18_gradcam_cifar100_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "img = cv2.imread(current_path + image_path)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_resnet18_gradcam_cifar100 = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100 = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100 = heatmap_resnet18_gradcam_cifar100 * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_cutout = heatmap_resnet18_gradcam_cifar100_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_da = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_da), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_da = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_da = heatmap_resnet18_gradcam_cifar100_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_resnet18_gradcam_cifar100_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_resnet18_gradcam_cifar100_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_resnet18_gradcam_cifar100_da_cutout = cv2.cvtColor(heatmap_resnet18_gradcam_cifar100_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_resnet18_gradcam_cifar100_da_cutout = heatmap_resnet18_gradcam_cifar100_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())"
   ],
   "id": "13d43b4b-9bab-40b5-962b-aa194479e2c9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the image and the Grad-CAM heatmap"
   ],
   "id": "f46c7ab5-8473-49d9-9cc4-85a8828e8064"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar100_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_resnet18_gradcam_cifar100 / 255)\n",
    "ax[1].set_title(predicted_class_resnet18_gradcam_cifar100)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_resnet18_gradcam_cifar100_cutout / 255)\n",
    "ax[2].set_title(predicted_class_resnet18_gradcam_cifar100)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_resnet18_gradcam_cifar100_da / 255)\n",
    "ax[3].set_title(predicted_class_resnet18_gradcam_cifar100_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_resnet18_gradcam_cifar100_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_resnet18_gradcam_cifar100_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "4b253bf4-36f4-42bb-af06-1c636f768f15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ENDS HERE"
   ],
   "id": "ec6c3ca5-ddc5-4571-92ae-1810120e73f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "2c28ea36-ba02-4511-83c5-742fc6a649e6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Implementation Grad-CAM for WideResNet Model"
   ],
   "id": "5aca2d5e-d966-4f17-b2c9-95b4bc98c86c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WideResNet Code"
   ],
   "id": "49485a69-615b-4254-9cf8-aff3d8694f5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideResNet\n",
    "\n",
    "# From https://github.com/uoguelph-mlrg/Cutout/blob/master/model/wide_resnet.py\n",
    "\n",
    "class BasicBlockWide(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlockWide, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) // 6\n",
    "        block = BasicBlockWide\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        # Register hooks for Grad-CAM\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.block3.register_forward_hook(self._store_activations_hook)\n",
    "        self.block3.register_backward_hook(self._store_gradients_hook)\n",
    "\n",
    "    def _store_activations_hook(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _store_gradients_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "80e08c62-cf73-43c2-9608-c8ac0ae56b51"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Implementation Grad-CAM for WideResNet Model for CIFAR-10"
   ],
   "id": "0dc45ae5-9a95-4f2b-bc93-3058273932be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wideresnet_gradcam_cifar10 = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10.load_state_dict(torch.load(current_path + \"checkpoints/wideresnet_cifar10.pt\"))\n",
    "wideresnet_gradcam_cifar10.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_cutout = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_cutout.load_state_dict(torch.load(current_path + \"checkpoints/wideresnet_cifar10_cutout.pt\"))\n",
    "wideresnet_gradcam_cifar10_cutout.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_da = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_da.load_state_dict(torch.load(current_path + \"checkpoints/wideresnet_cifar10_da.pt\"))\n",
    "wideresnet_gradcam_cifar10_da.eval()\n",
    "\n",
    "wideresnet_gradcam_cifar10_da_cutout = WideResNet(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n",
    "wideresnet_gradcam_cifar10_da_cutout.load_state_dict(torch.load(current_path + \"checkpoints/wideresnet_cifar10_da_cutout.pt\"))\n",
    "wideresnet_gradcam_cifar10_da_cutout.eval()"
   ],
   "id": "5426b4a4-87c1-4046-b1bd-8075aa8dab8d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try to see the result from the testloader of CIFAR-10 dataset"
   ],
   "id": "69ca4846-d5a7-4482-a9bd-5cfc2e2db7aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cifar10 = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar10)\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=1, shuffle=True, num_workers=2)\n"
   ],
   "id": "fa94bfa8-0db3-4578-a7c5-068ae16f34f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_classes = [\n",
    "    \"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\",\n",
    "    \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"\n",
    "]"
   ],
   "id": "8c27cd9e-7c95-4f07-b2a2-74583d60948f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the testloader\n",
    "images, labels = next(iter(testloader_cifar10))\n",
    "input_tensor = images  # As your batch_size is 1, you will have a single image here\n",
    "\n",
    "# Forward pass\n",
    "wideresnet_gradcam_cifar10.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_wideresnet_gradcam_cifar10 = output_wideresnet_gradcam_cifar10.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_cutout = output_wideresnet_gradcam_cifar10_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da = output_wideresnet_gradcam_cifar10_da.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da_cutout = output_wideresnet_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da = cifar10_classes[target_wideresnet_gradcam_cifar10_da.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da_cutout = cifar10_classes[target_wideresnet_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_wideresnet_gradcam_cifar10 = gradients_wideresnet_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_cutout = gradients_wideresnet_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da = gradients_wideresnet_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da_cutout = gradients_wideresnet_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_wideresnet_gradcam_cifar10 = (weights_wideresnet_gradcam_cifar10 * activations_wideresnet_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10 = F.relu(cam_wideresnet_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 = F.interpolate(cam_wideresnet_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10 = cam_wideresnet_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout = (weights_wideresnet_gradcam_cifar10_cutout * activations_wideresnet_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.relu(cam_wideresnet_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = cam_wideresnet_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da = (weights_wideresnet_gradcam_cifar10_da * activations_wideresnet_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da = F.relu(cam_wideresnet_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da = F.interpolate(cam_wideresnet_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da = cam_wideresnet_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = (weights_wideresnet_gradcam_cifar10_da_cutout * activations_wideresnet_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.relu(cam_wideresnet_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = cam_wideresnet_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 -= cam_wideresnet_gradcam_cifar10.min()\n",
    "cam_wideresnet_gradcam_cifar10 /= cam_wideresnet_gradcam_cifar10.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout -= cam_wideresnet_gradcam_cifar10_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_cutout /= cam_wideresnet_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da -= cam_wideresnet_gradcam_cifar10_da.min()\n",
    "cam_wideresnet_gradcam_cifar10_da /= cam_wideresnet_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout -= cam_wideresnet_gradcam_cifar10_da_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout /= cam_wideresnet_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Since the images from the dataloader are normalized, you have to denormalize them before plotting\n",
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])\n",
    "img = images.squeeze().detach().cpu() * std[..., None, None] + mean[..., None, None]\n",
    "img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10 = heatmap_wideresnet_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_cutout = heatmap_wideresnet_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da = heatmap_wideresnet_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da_cutout = heatmap_wideresnet_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, constrained_layout=True)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_wideresnet_gradcam_cifar10 / 255)\n",
    "ax[1].set_title('Pred: ' + predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_wideresnet_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_wideresnet_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_wideresnet_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_wideresnet_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_wideresnet_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()"
   ],
   "id": "1777e749-cb99-4910-a54b-b3f076a0557c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try to load your image, preprocess it and convert it into a PyTorch tensor. Choose an image that is in the CIFAR-10 classes (airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks). The preprocessing steps should be the same as the ones you used for training your model. Let’s say you have an image `image.jpeg`:"
   ],
   "id": "8af48d37-3984-4553-a85a-8fd236fa6aaa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = \"image.jpeg\"\n",
    "image = Image.open(current_path + image_path)\n",
    "\n",
    "# Define the transformations: resize, to tensor, normalize (replace the mean and std with values you used for training)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # add batch dimension.  C,H,W => B,C,H,W"
   ],
   "id": "edb5839e-23c3-4f2f-9f65-e78189424951"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Grad-CAM"
   ],
   "id": "b059a047-5f87-440f-b229-1250ceb865db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "wideresnet_gradcam_cifar10.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da(input_tensor)\n",
    "\n",
    "wideresnet_gradcam_cifar10_da_cutout.zero_grad()\n",
    "output_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout(input_tensor)\n",
    "\n",
    "# Get the index of the max log-probability\n",
    "target_wideresnet_gradcam_cifar10 = output_wideresnet_gradcam_cifar10.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_cutout = output_wideresnet_gradcam_cifar10_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_cutout.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da = output_wideresnet_gradcam_cifar10_da.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da.max().backward()\n",
    "\n",
    "target_wideresnet_gradcam_cifar10_da_cutout = output_wideresnet_gradcam_cifar10_da_cutout.argmax(1)\n",
    "output_wideresnet_gradcam_cifar10_da_cutout.max().backward()\n",
    "\n",
    "# Map the predicted class indices to the class labels\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10 = cifar10_classes[target_wideresnet_gradcam_cifar10_cutout.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da = cifar10_classes[target_wideresnet_gradcam_cifar10_da.item()]\n",
    "predicted_class_wideresnet_gradcam_cifar10_da_cutout = cifar10_classes[target_wideresnet_gradcam_cifar10_da_cutout.item()]\n",
    "\n",
    "\n",
    "# Get the gradients and activations\n",
    "gradients_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10 = wideresnet_gradcam_cifar10.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_cutout = wideresnet_gradcam_cifar10_cutout.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da = wideresnet_gradcam_cifar10_da.activations.detach().cpu()\n",
    "\n",
    "gradients_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.gradients.detach().cpu()\n",
    "activations_wideresnet_gradcam_cifar10_da_cutout = wideresnet_gradcam_cifar10_da_cutout.activations.detach().cpu()\n",
    "\n",
    "\n",
    "# Calculate the weights\n",
    "weights_wideresnet_gradcam_cifar10 = gradients_wideresnet_gradcam_cifar10.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_cutout = gradients_wideresnet_gradcam_cifar10_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da = gradients_wideresnet_gradcam_cifar10_da.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "weights_wideresnet_gradcam_cifar10_da_cutout = gradients_wideresnet_gradcam_cifar10_da_cutout.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "# Calculate the weighted sum of activations (Grad-CAM)\n",
    "cam_wideresnet_gradcam_cifar10 = (weights_wideresnet_gradcam_cifar10 * activations_wideresnet_gradcam_cifar10).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10 = F.relu(cam_wideresnet_gradcam_cifar10)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 = F.interpolate(cam_wideresnet_gradcam_cifar10, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10 = cam_wideresnet_gradcam_cifar10.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout = (weights_wideresnet_gradcam_cifar10_cutout * activations_wideresnet_gradcam_cifar10_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.relu(cam_wideresnet_gradcam_cifar10_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_cutout = cam_wideresnet_gradcam_cifar10_cutout.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da = (weights_wideresnet_gradcam_cifar10_da * activations_wideresnet_gradcam_cifar10_da).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da = F.relu(cam_wideresnet_gradcam_cifar10_da)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da = F.interpolate(cam_wideresnet_gradcam_cifar10_da, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da = cam_wideresnet_gradcam_cifar10_da.squeeze().numpy()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = (weights_wideresnet_gradcam_cifar10_da_cutout * activations_wideresnet_gradcam_cifar10_da_cutout).sum(dim=1, keepdim=True)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.relu(cam_wideresnet_gradcam_cifar10_da_cutout)  # apply ReLU to the heatmap\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = F.interpolate(cam_wideresnet_gradcam_cifar10_da_cutout, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout = cam_wideresnet_gradcam_cifar10_da_cutout.squeeze().numpy()\n",
    "\n",
    "\n",
    "# Normalize the heatmap\n",
    "cam_wideresnet_gradcam_cifar10 -= cam_wideresnet_gradcam_cifar10.min()\n",
    "cam_wideresnet_gradcam_cifar10 /= cam_wideresnet_gradcam_cifar10.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_cutout -= cam_wideresnet_gradcam_cifar10_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_cutout /= cam_wideresnet_gradcam_cifar10_cutout.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da -= cam_wideresnet_gradcam_cifar10_da.min()\n",
    "cam_wideresnet_gradcam_cifar10_da /= cam_wideresnet_gradcam_cifar10_da.max()\n",
    "\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout -= cam_wideresnet_gradcam_cifar10_da_cutout.min()\n",
    "cam_wideresnet_gradcam_cifar10_da_cutout /= cam_wideresnet_gradcam_cifar10_da_cutout.max()\n",
    "\n",
    "# Load the original image\n",
    "img = cv2.imread(current_path + image_path)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Superimpose the heatmap onto the original image\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10 = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10 = heatmap_wideresnet_gradcam_cifar10 * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_cutout = heatmap_wideresnet_gradcam_cifar10_cutout * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da = heatmap_wideresnet_gradcam_cifar10_da * 0.4 + img * 255\n",
    "\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.applyColorMap(np.uint8(255 * cam_wideresnet_gradcam_cifar10_da_cutout), cv2.COLORMAP_JET)\n",
    "heatmap_wideresnet_gradcam_cifar10_da_cutout = cv2.cvtColor(heatmap_wideresnet_gradcam_cifar10_da_cutout, cv2.COLOR_BGR2RGB)\n",
    "superimposed_img_wideresnet_gradcam_cifar10_da_cutout = heatmap_wideresnet_gradcam_cifar10_da_cutout * 0.4 + img * 255\n",
    "\n",
    "class_label = str(labels.item())\n",
    "\n",
    "# Display the original image and the Grad-CAM\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, constrained_layout=True)\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('(Class: ' + cifar10_classes[int(class_label)] + ')')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(superimposed_img_wideresnet_gradcam_cifar10 / 255)\n",
    "ax[1].set_title('Pred: ' + predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(superimposed_img_wideresnet_gradcam_cifar10_cutout / 255)\n",
    "ax[2].set_title(predicted_class_wideresnet_gradcam_cifar10)\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(superimposed_img_wideresnet_gradcam_cifar10_da / 255)\n",
    "ax[3].set_title(predicted_class_wideresnet_gradcam_cifar10_da)\n",
    "ax[3].axis('off')\n",
    "ax[4].imshow(superimposed_img_wideresnet_gradcam_cifar10_da_cutout / 255)\n",
    "ax[4].set_title(predicted_class_wideresnet_gradcam_cifar10_da_cutout)\n",
    "ax[4].axis('off')\n",
    "\n",
    "fig.suptitle(\"Original Image - Grad-CAM -  GC with CO - GC with DA - GC with CO&Da\")\n",
    "plt.show()"
   ],
   "id": "42e5ce5e-c87c-43c4-9e5f-196926195975"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
