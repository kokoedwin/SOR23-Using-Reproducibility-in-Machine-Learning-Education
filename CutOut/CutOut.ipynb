{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c130e5-e2ce-4664-8409-87461e11c146",
   "metadata": {},
   "source": [
    "# Reproducibility: Cutout\n",
    "\n",
    "### Original Paper: Improved Regularization of Convolutional Neural Networks with Cutout\n",
    "\n",
    "### Original Code: <https://github.com/uoguelph-mlrg/Cutout>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8d5ed-2df0-4785-a549-0d691b017ce6",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This Jupyter notebook is designed to illustrate the implementation and usage of the CutOut data augmentation technique in deep learning, specifically in the context of Convolutional Neural Networks (CNNs).\n",
    "\n",
    "### CutOut: An Overview\n",
    "\n",
    "CutOut is a regularization and data augmentation technique for convolutional neural networks (CNNs). It involves randomly masking out square regions of input during training. This helps to improve the robustness and overall performance of CNNs by encouraging the network to better utilize the full context of the image, rather than relying on the presence of a small set of specific visual features.\n",
    "\n",
    "CutOut is computationally efficient as it can be applied during data loading in parallel with the main training task. It can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance.\n",
    "\n",
    "The technique has been evaluated with state-of-the-art architectures on popular image recognition datasets such as CIFAR-10, CIFAR-100, and SVHN, often achieving state-of-the-art or near state-of-the-art results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16233f08-52af-4040-90b7-32c5f952cd49",
   "metadata": {},
   "source": [
    "# 2. Setting Up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e42a4-8afb-4678-b233-5e152975a4c9",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7b65-22ef-451b-9f5a-5c9995331a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee43a88-96a3-41d0-a23d-ef932efb9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D9nl5D7QC8Kg",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/content/checkpoints'):\n",
    "    os.makedirs('/content/checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kTJayODE4tqA",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wePTccm-5Jfh",
   "metadata": {},
   "source": [
    "## Cutout Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8hBvsq8A8WPD",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G6qClZBC5PWp",
   "metadata": {},
   "source": [
    "## Image without Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dxxPDv3HM-Ud",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "outputId": "20a7d49f-7f40-48b0-fd3f-4200fd39bbb4"
   },
   "outputs": [],
   "source": [
    "# Load an image\n",
    "img = Image.open('/content/sample.png')\n",
    "\n",
    "# Convert the image to a PyTorch tensor\n",
    "img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img_tensor.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2blWk9iB5VZJ",
   "metadata": {},
   "source": [
    "## Image with Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NOKi5DGNCpc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "outputId": "f4710560-963f-4a50-ffd7-3242f364d542"
   },
   "outputs": [],
   "source": [
    "# Create a Cutout object\n",
    "cutout = Cutout(n_holes=1, length=300)\n",
    "\n",
    "# Apply Cutout to the image\n",
    "img_tensor_cutout = cutout(img_tensor)\n",
    "\n",
    "# Convert the tensor back to an image for visualization\n",
    "img_cutout = transforms.ToPILImage()(img_tensor_cutout)\n",
    "\n",
    "# Display the image with cutout applied\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img_tensor_cutout.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HLiZirvA5dfE",
   "metadata": {},
   "source": [
    "## Implement Cutout on CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FiuWkXnrQrs9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #,\n",
    "    #Cutout(n_holes=1, length=16)  # Cutout applied here\n",
    "])\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z1WfijBcRzTd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "29122b6a-cacf-44cd-f009-98f4c6ccbac1"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset with transformations applied\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gWt7F2tEQrvq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "3f422d0a-aa37-4bb5-87fa-e3c9110ea8a9"
   },
   "outputs": [],
   "source": [
    "# Get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images before Cutout\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mWDUpa-KSDta",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "a22fee56-b6eb-4e04-c066-ebbab49d0d4c"
   },
   "outputs": [],
   "source": [
    "# Apply Cutout and show images after\n",
    "cutout_images = torch.stack([Cutout(n_holes=1, length=16)(img) for img in images])\n",
    "imshow(torchvision.utils.make_grid(cutout_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cyqBjZTW4tyV",
   "metadata": {},
   "source": [
    "# 4. Methods and Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iMV_N3Es5lkG",
   "metadata": {},
   "source": [
    "## ResNet Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DvC8ZTlGTlxR",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "\n",
    "'''ResNet18/34/50/101/152 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "  return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = conv3x3(planes, planes)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "      self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "  expansion = 4\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(Bottleneck, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "      self.shortcut = nn.Sequential(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),nn.BatchNorm2d(self.expansion*planes))\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = F.relu(self.bn2(self.conv2(out)))\n",
    "    out = self.bn3(self.conv3(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "  def __init__(self, block, num_blocks, num_classes=10):\n",
    "    super(ResNet, self).__init__()\n",
    "    self.in_planes = 64\n",
    "\n",
    "    self.conv1 = conv3x3(3,64)\n",
    "    self.bn1 = nn.BatchNorm2d(64)\n",
    "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "  def _make_layer(self, block, planes, num_blocks, stride):\n",
    "    strides = [stride] + [1]*(num_blocks-1)\n",
    "    layers = []\n",
    "    for stride in strides:\n",
    "      layers.append(block(self.in_planes, planes, stride))\n",
    "      self.in_planes = planes * block.expansion\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.layer1(out)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    out = self.layer4(out)\n",
    "    out = F.avg_pool2d(out, 4)\n",
    "    out = out.view(out.size(0), -1)\n",
    "    out = self.linear(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "  return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
    "\n",
    "def ResNet34(num_classes=10):\n",
    "  return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet50(num_classes=10):\n",
    "  return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
    "\n",
    "def ResNet101(num_classes=10):\n",
    "  return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
    "\n",
    "def ResNet152(num_classes=10):\n",
    "  return ResNet(Bottleneck, [3,8,36,3], num_classes)\n",
    "\n",
    "def test_resnet():\n",
    "  net = ResNet50()\n",
    "  y = net(Variable(torch.randn(1,3,32,32)))\n",
    "  print(y.size())\n",
    "\n",
    "# test_resnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vHqVn5WX5onk",
   "metadata": {},
   "source": [
    "## WideResNet Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yVyKVrpCTwJG",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideResNet\n",
    "\n",
    "# From https://github.com/xternalz/WideResNet-pytorch\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(nb_layers):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XGFkPhB9ncnB",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVLogger():\n",
    "    def __init__(self, args, fieldnames, filename='log.csv'):\n",
    "\n",
    "        self.filename = filename\n",
    "        self.csv_file = open(filename, 'w')\n",
    "\n",
    "        # Write model configuration at top of csv\n",
    "        writer = csv.writer(self.csv_file)\n",
    "        for arg in vars(args):\n",
    "            writer.writerow([arg, getattr(args, arg)])\n",
    "        writer.writerow([''])\n",
    "\n",
    "        self.writer = csv.DictWriter(self.csv_file, fieldnames=fieldnames)\n",
    "        self.writer.writeheader()\n",
    "\n",
    "        self.csv_file.flush()\n",
    "\n",
    "    def writerow(self, row):\n",
    "        self.writer.writerow(row)\n",
    "        self.csv_file.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53JsJu4b4t1l",
   "metadata": {},
   "source": [
    "# 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zKiNzV9teviL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train.py --dataset cifar10 --model resnet18 --data_augmentation --cutout --length 16\n",
    "# run train.py --dataset cifar100 --model resnet18 --data_augmentation --cutout --length 8\n",
    "# run train.py --dataset svhn --model wideresnet --learning_rate 0.01 --epochs 160 --cutout --length 20\n",
    "\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, transforms\n",
    "'''\n",
    "\n",
    "#from util.misc import CSVLogger\n",
    "#from util.cutout import Cutout\n",
    "\n",
    "#from model.resnet import ResNet18\n",
    "#from model.wide_resnet import WideResNet\n",
    "'''\n",
    "model_options = ['resnet18', 'wideresnet']\n",
    "dataset_options = ['cifar10', 'cifar100', 'svhn']\n",
    "\n",
    "parser = argparse.ArgumentParser(description='CNN')\n",
    "parser.add_argument('--dataset', '-d', default='cifar10',\n",
    "                    choices=dataset_options)\n",
    "parser.add_argument('--model', '-a', default='resnet18',\n",
    "                    choices=model_options)\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=200,\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--data_augmentation', action='store_true', default=False,\n",
    "                    help='augment data by flipping and cropping')\n",
    "parser.add_argument('--cutout', action='store_true', default=False,\n",
    "                    help='apply cutout')\n",
    "parser.add_argument('--n_holes', type=int, default=1,\n",
    "                    help='number of holes to cut out from image')\n",
    "parser.add_argument('--length', type=int, default=16,\n",
    "                    help='length of the holes')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "                    help='random seed (default: 1)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "'''\n",
    "\n",
    "def main(args):\n",
    "  args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "  cudnn.benchmark = True  # Should make training should go faster for large models\n",
    "\n",
    "\n",
    "  torch.manual_seed(args.seed)\n",
    "  if args.cuda:\n",
    "      torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "  test_id = args.dataset + '_' + args.model\n",
    "\n",
    "  print(args)\n",
    "\n",
    "  # Image Preprocessing\n",
    "  if args.dataset == 'svhn':\n",
    "      normalize = transforms.Normalize(mean=[x / 255.0 for x in[109.9, 109.7, 113.8]],\n",
    "                                      std=[x / 255.0 for x in [50.1, 50.6, 50.8]])\n",
    "  else:\n",
    "      normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                      std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "  train_transform = transforms.Compose([])\n",
    "  if args.data_augmentation:\n",
    "      train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
    "      train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
    "  train_transform.transforms.append(transforms.ToTensor())\n",
    "  train_transform.transforms.append(normalize)\n",
    "  if args.cutout:\n",
    "      train_transform.transforms.append(Cutout(n_holes=args.n_holes, length=args.length))\n",
    "\n",
    "\n",
    "  test_transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      normalize])\n",
    "\n",
    "  if args.dataset == 'cifar10':\n",
    "      num_classes = 10\n",
    "      train_dataset = datasets.CIFAR10(root='data/',\n",
    "                                      train=True,\n",
    "                                      transform=train_transform,\n",
    "                                      download=True)\n",
    "\n",
    "      test_dataset = datasets.CIFAR10(root='data/',\n",
    "                                      train=False,\n",
    "                                      transform=test_transform,\n",
    "                                      download=True)\n",
    "  elif args.dataset == 'cifar100':\n",
    "      num_classes = 100\n",
    "      train_dataset = datasets.CIFAR100(root='data/',\n",
    "                                        train=True,\n",
    "                                        transform=train_transform,\n",
    "                                        download=True)\n",
    "\n",
    "      test_dataset = datasets.CIFAR100(root='data/',\n",
    "                                      train=False,\n",
    "                                      transform=test_transform,\n",
    "                                      download=True)\n",
    "  elif args.dataset == 'svhn':\n",
    "      num_classes = 10\n",
    "      train_dataset = datasets.SVHN(root='data/',\n",
    "                                    split='train',\n",
    "                                    transform=train_transform,\n",
    "                                    download=True)\n",
    "\n",
    "      extra_dataset = datasets.SVHN(root='data/',\n",
    "                                    split='extra',\n",
    "                                    transform=train_transform,\n",
    "                                    download=True)\n",
    "\n",
    "      # Combine both training splits (https://arxiv.org/pdf/1605.07146.pdf)\n",
    "      data = np.concatenate([train_dataset.data, extra_dataset.data], axis=0)\n",
    "      labels = np.concatenate([train_dataset.labels, extra_dataset.labels], axis=0)\n",
    "      train_dataset.data = data\n",
    "      train_dataset.labels = labels\n",
    "\n",
    "      test_dataset = datasets.SVHN(root='data/',\n",
    "                                  split='test',\n",
    "                                  transform=test_transform,\n",
    "                                  download=True)\n",
    "\n",
    "  # Data Loader (Input Pipeline)\n",
    "  train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=2)\n",
    "\n",
    "  test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=2)\n",
    "\n",
    "  if args.model == 'resnet18':\n",
    "      cnn = ResNet18(num_classes=num_classes)\n",
    "  elif args.model == 'wideresnet':\n",
    "      if args.dataset == 'svhn':\n",
    "          cnn = WideResNet(depth=16, num_classes=num_classes, widen_factor=8,\n",
    "                          dropRate=0.4)\n",
    "      else:\n",
    "          cnn = WideResNet(depth=28, num_classes=num_classes, widen_factor=10,\n",
    "                          dropRate=0.3)\n",
    "\n",
    "  cnn = cnn.cuda()\n",
    "  criterion = nn.CrossEntropyLoss().cuda()\n",
    "  cnn_optimizer = torch.optim.SGD(cnn.parameters(), lr=args.learning_rate,\n",
    "                                  momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
    "\n",
    "  if args.dataset == 'svhn':\n",
    "      scheduler = MultiStepLR(cnn_optimizer, milestones=[80, 120], gamma=0.1)\n",
    "  else:\n",
    "      scheduler = MultiStepLR(cnn_optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
    "\n",
    "  filename = 'logs/' + test_id + '.csv'\n",
    "  csv_logger = CSVLogger(args=args, fieldnames=['epoch', 'train_acc', 'test_acc'], filename=filename)\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      cnn.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "      correct = 0.\n",
    "      total = 0.\n",
    "      for images, labels in loader:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "          with torch.no_grad():\n",
    "              pred = cnn(images)\n",
    "\n",
    "          pred = torch.max(pred.data, 1)[1]\n",
    "          total += labels.size(0)\n",
    "          correct += (pred == labels).sum().item()\n",
    "\n",
    "      val_acc = correct / total\n",
    "      cnn.train()\n",
    "      return val_acc\n",
    "\n",
    "\n",
    "  for epoch in range(args.epochs):\n",
    "\n",
    "      xentropy_loss_avg = 0.\n",
    "      correct = 0.\n",
    "      total = 0.\n",
    "\n",
    "      progress_bar = tqdm(train_loader)\n",
    "      for i, (images, labels) in enumerate(progress_bar):\n",
    "          progress_bar.set_description('Epoch ' + str(epoch))\n",
    "\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "          cnn.zero_grad()\n",
    "          pred = cnn(images)\n",
    "\n",
    "          xentropy_loss = criterion(pred, labels)\n",
    "          xentropy_loss.backward()\n",
    "          cnn_optimizer.step()\n",
    "\n",
    "          xentropy_loss_avg += xentropy_loss.item()\n",
    "\n",
    "          # Calculate running average of accuracy\n",
    "          pred = torch.max(pred.data, 1)[1]\n",
    "          total += labels.size(0)\n",
    "          correct += (pred == labels.data).sum().item()\n",
    "          accuracy = correct / total\n",
    "\n",
    "          progress_bar.set_postfix(\n",
    "              xentropy='%.3f' % (xentropy_loss_avg / (i + 1)),\n",
    "              acc='%.3f' % accuracy)\n",
    "\n",
    "      test_acc = test(test_loader)\n",
    "      tqdm.write('test_acc: %.3f' % (test_acc))\n",
    "\n",
    "      scheduler.step(epoch)  # Use this line for PyTorch <1.4\n",
    "      # scheduler.step()     # Use this line for PyTorch >=1.4\n",
    "\n",
    "      row = {'epoch': str(epoch), 'train_acc': str(accuracy), 'test_acc': str(test_acc)}\n",
    "      csv_logger.writerow(row)\n",
    "\n",
    "  torch.save(cnn.state_dict(), 'checkpoints/' + test_id + '.pt')\n",
    "  csv_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LSqFDwY2kXe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    dataset = 'cifar10'\n",
    "    model = 'resnet18'\n",
    "    batch_size = 128\n",
    "    epochs = 200\n",
    "    learning_rate = 0.1\n",
    "    data_augmentation = False\n",
    "    cutout = False\n",
    "    n_holes = 1\n",
    "    length = 16\n",
    "    no_cuda = False\n",
    "    seed = 0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XPoNYqgJk3Bl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5587dc4a-609d-446a-ba21-42a49371e970"
   },
   "outputs": [],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XHVRxUro4t4b",
   "metadata": {},
   "source": [
    "# 6. Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W5JJ1ZeT57gD",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vofk1uIX4t7Y",
   "metadata": {},
   "source": [
    "# 7. Interactive Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NPKYdKrx5EHo",
   "metadata": {},
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2HK7vaSgEIs0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ROvEGMCEUuF",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yAgc1-3fFANK",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
